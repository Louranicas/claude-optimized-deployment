# Security Chapter Extract
Book: Hamed Tabrizchi_ Ali Aghasi - Federated Cyber Intelligence _ Federated Learning for Cybersecurity (2025, Springer Nature Switzerland) - libgen.li
Chapter: 1 - Initialize global model weights W_global2. For each round t do:3.  Select random set of K clients from all clients4.  Initialize an empty set of client model weights: W_clients = []5.  For each client k in a random subset of clients do:6.   Initialize local model weights: W_local = W_global7.   For each local epoch i from 1 to E do:8.    For each minibatch B in client’s local dataset do:9.     W_local = LocalUpdate(B, W_local)10.   Append local model weights to client model weights11. W_global = average(W_clients)In this pseudocode:W_global represents the global model weights.W_clients is a set of model weights from each client.W_local represents the local model weights for each client.LocalUpdate(B,W_local) is a function that updates W_local based on the mini batch B.average(W_clients) is a function that computes the average of W_clients.At the beginning of the federated learning process, the server selects a random set of clients to participate and initializes them with a fresh model. Subsequently, several rounds of updates and averaging commence. In each round, each selected client trains the newly received global model using its local data. This local training consists of the same numbers of epochs until convergence. The locally updated model weights are then sent back to the server for averaging. This process continues until the server decides to terminate it. Thus, in each round t, the following operations are performed:1.Select random clients. 2.Initialize local models with the global model. 3.Train local models on local data for several epochs. 4.Send local model updates to the server. 5.Average the local model updates to update the global model. Following equations describes the local training and global aggregating procedures in FedAVG (2.1) (2.2)Equation (2.1) points out the local training phase where each client k using global model aggregated at round t performs training to reach the converged model .The aggregation phase, Eq. (2.2), contains a weighted average over all received local models.  actually indicates how much data in comparison to all data resides in client k. It is completely expected that the weight of clients with more data must be more in the global model. An overview of the FedAVG is illustrated in Fig. 2.2.Diagram illustrating a federated learning process. A central server sends model updates, denoted as Wt, to multiple clients (Client 1, Client 2, up to Client k). Each client performs local updates over E epochs and returns updated models, W_t+1, to the server. Blue arrows indicate local model updates, while orange dashed arrows represent global model updates.Fig. 2.2FedAvg operation schemeThe performance of the aggregated model in FedAvg could be improved if the model parameters of the clients were aggregated after each local epoch instead of waiting until all training epochs are completed. This is the core idea behind the FedSGD algorithm, introduced in the same paper following FedAvg. In FedSGD, after each local epoch, the clients send their gradients to the server. Unlike in FedAvg, where simple averaging is performed, FedSGD aggregates the gradients and optimizes the loss function using these local gradients (gk). The gradient descent formula, Eq. (2.3), is applied on the server, making the aggregation more efficient and potentially enhancing model performance. (2.3)The primary difference in FedSGD is the use of a weighted average of all collected gradients. After performing backward propagation, each client sends its calculated gradient to the server, which then updates the global model weights. The updated weights are subsequently broadcasted back to the clients to start the next epoch. It is evident that this approach incurs a significantly higher communication cost compared to the FedAvg algorithm.The transition from FedAVG to FedSGD can be rationalized by considering the trade-off between communication efficiency and model performance. While FedAVG reduces the communication cost, it might have poorer performance due to the naive method of averaging the model weight. Therefore, if the communication cost is not a concern and the focus is on improving the model performance, transitioning to FedSGD could be a rational choice.In the real world, clients often face issues such as poor connectivity, power shortages, or CPU overutilization, leading to incomplete training epochs. In FedAvg, stragglers are simply dropped, degrading model performance due to the loss of valuable data. To address this heterogeneity,Tian Li et al. proposed the FedProx algorithm in [8]. FedProx accommodates varying numbers of epochs, allowing some devices to perform fewer epochs based on current system constraints.Figure 2.3 illustrates a set of clients selected for participation. A subset of these clients completes their training epochs (active set), while others become stragglers. FedProx permits stragglers to upload their partially trained models.Diagram illustrating two sets within a rectangular box. The left section, labeled "Active Set," contains three shaded rectangles. The right section, labeled "Straggler Set," contains two shaded rectangles. Below, the timeline is divided into "E epochs" under the Active Set and "Less than E epochs" under the Straggler Set.Fig. 2.3FedProx client partitioningWhile FedAvg assumes that data are independent and identically distributed and guarantees convergence under this assumption, this is often unrealistic. FedProx generalizes FedAvg to handle non-IID data. The global model weights are superior to any individual client model because the server aggregates more data. Therefore, if a client’s model parameters approach the global model parameters, it indicates the client is on the right path. FedProx incorporates a proximal term into the client’s learning equation to control the update, ensuring convergence. (2.4)The proximal term, μ(wt − wG), guides the local model by considering the global model direction, facilitating convergence even with non-IID data.FedProx addresses the issues of client heterogeneity and non-IID data by allowing flexible training epochs and incorporating a proximal term that regulates local updates. This makes FedProx a more robust and adaptable algorithm for federated learning in real-world scenarios, where client capabilities and data distributions are often diverse and unpredictable.FedAvg [6], FedSGD [8], and FedProx [9] represent foundational and evolving approaches to federated learning, each addressing specific challenges inherent in decentralized machine learning. FedAvg introduced the basic concept of federated learning by averaging locally trained model weights, setting the stage for more sophisticated algorithms. FedSGD built upon this by aggregating gradients after each local epoch, optimizing the global model more frequently but at a higher communication cost. FedProx further advanced the field by accommodating client heterogeneity and handling non-IID data through a proximal term that guides local updates to align with the global model. Together, these algorithms form the backbone of federated learning systems, each contributing unique solutions to enhance performance, robustness, and scalability in real-world applications. As federated learning continues to evolve, these foundational algorithms will undoubtedly inspire future innovations and adaptations to meet emerging challenges and opportunities.2.2.3.1 Difference of Federated Learning’s Workflow and ArchitectureThere are distinct aspects to the federated learning’s workflow and architecture which relate to its design and function. The architecture of federated learning describes the structural design of the system. This includes the arrangement and relationships of its core components such as clients, a central server, an aggregator, communication networks, and security mechanisms. It defines how these components are organized and interact to facilitate the overall system’s operation. In contrast, as mentioned in the previous section, the workflow of federated learning refers to the sequence of processes and activities carried out within this architectural framework. It details the step-by-step procedures involved in training and updating the machine learning model, from the initial model distribution by the central server to the clients, through local training on clients’ devices, to the aggregation of updates and the iterative refinement of the model. In a nutshell, while the architecture provides the blueprint for the system’s infrastructure, the workflow describes the dynamic operations and tasks executed within that infrastructure to achieve federated learning objectives [10].
Security Relevance Score: 11
Word Count: 7924
Extracted: 2025-06-13 23:40:53

---

Initialize global model weights W_global2. For each round t do:3.  Select random set of K clients from all clients4.  Initialize an empty set of client model weights: W_clients = []5.  For each client k in a random subset of clients do:6.   Initialize local model weights: W_local = W_global7.   For each local epoch i from 1 to E do:8.    For each minibatch B in client’s local dataset do:9.     W_local = LocalUpdate(B, W_local)10.   Append local model weights to client model weights11. W_global = average(W_clients)In this pseudocode:W_global represents the global model weights.W_clients is a set of model weights from each client.W_local represents the local model weights for each client.LocalUpdate(B,W_local) is a function that updates W_local based on the mini batch B.average(W_clients) is a function that computes the average of W_clients.At the beginning of the federated learning process, the server selects a random set of clients to participate and initializes them with a fresh model. Subsequently, several rounds of updates and averaging commence. In each round, each selected client trains the newly received global model using its local data. This local training consists of the same numbers of epochs until convergence. The locally updated model weights are then sent back to the server for averaging. This process continues until the server decides to terminate it. Thus, in each round t, the following operations are performed:1.Select random clients. 2.Initialize local models with the global model. 3.Train local models on local data for several epochs. 4.Send local model updates to the server. 5.Average the local model updates to update the global model. Following equations describes the local training and global aggregating procedures in FedAVG (2.1) (2.2)Equation (2.1) points out the local training phase where each client k using global model aggregated at round t performs training to reach the converged model .The aggregation phase, Eq. (2.2), contains a weighted average over all received local models.  actually indicates how much data in comparison to all data resides in client k. It is completely expected that the weight of clients with more data must be more in the global model. An overview of the FedAVG is illustrated in Fig. 2.2.Diagram illustrating a federated learning process. A central server sends model updates, denoted as Wt, to multiple clients (Client 1, Client 2, up to Client k). Each client performs local updates over E epochs and returns updated models, W_t+1, to the server. Blue arrows indicate local model updates, while orange dashed arrows represent global model updates.Fig. 2.2FedAvg operation schemeThe performance of the aggregated model in FedAvg could be improved if the model parameters of the clients were aggregated after each local epoch instead of waiting until all training epochs are completed. This is the core idea behind the FedSGD algorithm, introduced in the same paper following FedAvg. In FedSGD, after each local epoch, the clients send their gradients to the server. Unlike in FedAvg, where simple averaging is performed, FedSGD aggregates the gradients and optimizes the loss function using these local gradients (gk). The gradient descent formula, Eq. (2.3), is applied on the server, making the aggregation more efficient and potentially enhancing model performance. (2.3)The primary difference in FedSGD is the use of a weighted average of all collected gradients. After performing backward propagation, each client sends its calculated gradient to the server, which then updates the global model weights. The updated weights are subsequently broadcasted back to the clients to start the next epoch. It is evident that this approach incurs a significantly higher communication cost compared to the FedAvg algorithm.The transition from FedAVG to FedSGD can be rationalized by considering the trade-off between communication efficiency and model performance. While FedAVG reduces the communication cost, it might have poorer performance due to the naive method of averaging the model weight. Therefore, if the communication cost is not a concern and the focus is on improving the model performance, transitioning to FedSGD could be a rational choice.In the real world, clients often face issues such as poor connectivity, power shortages, or CPU overutilization, leading to incomplete training epochs. In FedAvg, stragglers are simply dropped, degrading model performance due to the loss of valuable data. To address this heterogeneity,Tian Li et al. proposed the FedProx algorithm in [8]. FedProx accommodates varying numbers of epochs, allowing some devices to perform fewer epochs based on current system constraints.Figure 2.3 illustrates a set of clients selected for participation. A subset of these clients completes their training epochs (active set), while others become stragglers. FedProx permits stragglers to upload their partially trained models.Diagram illustrating two sets within a rectangular box. The left section, labeled "Active Set," contains three shaded rectangles. The right section, labeled "Straggler Set," contains two shaded rectangles. Below, the timeline is divided into "E epochs" under the Active Set and "Less than E epochs" under the Straggler Set.Fig. 2.3FedProx client partitioningWhile FedAvg assumes that data are independent and identically distributed and guarantees convergence under this assumption, this is often unrealistic. FedProx generalizes FedAvg to handle non-IID data. The global model weights are superior to any individual client model because the server aggregates more data. Therefore, if a client’s model parameters approach the global model parameters, it indicates the client is on the right path. FedProx incorporates a proximal term into the client’s learning equation to control the update, ensuring convergence. (2.4)The proximal term, μ(wt − wG), guides the local model by considering the global model direction, facilitating convergence even with non-IID data.FedProx addresses the issues of client heterogeneity and non-IID data by allowing flexible training epochs and incorporating a proximal term that regulates local updates. This makes FedProx a more robust and adaptable algorithm for federated learning in real-world scenarios, where client capabilities and data distributions are often diverse and unpredictable.FedAvg [6], FedSGD [8], and FedProx [9] represent foundational and evolving approaches to federated learning, each addressing specific challenges inherent in decentralized machine learning. FedAvg introduced the basic concept of federated learning by averaging locally trained model weights, setting the stage for more sophisticated algorithms. FedSGD built upon this by aggregating gradients after each local epoch, optimizing the global model more frequently but at a higher communication cost. FedProx further advanced the field by accommodating client heterogeneity and handling non-IID data through a proximal term that guides local updates to align with the global model. Together, these algorithms form the backbone of federated learning systems, each contributing unique solutions to enhance performance, robustness, and scalability in real-world applications. As federated learning continues to evolve, these foundational algorithms will undoubtedly inspire future innovations and adaptations to meet emerging challenges and opportunities.2.2.3.1 Difference of Federated Learning’s Workflow and ArchitectureThere are distinct aspects to the federated learning’s workflow and architecture which relate to its design and function. The architecture of federated learning describes the structural design of the system. This includes the arrangement and relationships of its core components such as clients, a central server, an aggregator, communication networks, and security mechanisms. It defines how these components are organized and interact to facilitate the overall system’s operation. In contrast, as mentioned in the previous section, the workflow of federated learning refers to the sequence of processes and activities carried out within this architectural framework. It details the step-by-step procedures involved in training and updating the machine learning model, from the initial model distribution by the central server to the clients, through local training on clients’ devices, to the aggregation of updates and the iterative refinement of the model. In a nutshell, while the architecture provides the blueprint for the system’s infrastructure, the workflow describes the dynamic operations and tasks executed within that infrastructure to achieve federated learning objectives [10].
2.2.3.2 General Architectures of Federated Learning SystemsWithin the domain of federated learning, there are several architectures, primarily categorized into horizontal federated learning, vertical federated learning, hybrid federated learning and federated transfer learning. These categorizations are based on the nature of the data partitioning and the type of learning involved [9].2.2.3.2.1 Horizontal Federated Learning (HFL)Horizontal federated learning, also known as sample-based federated learning, applies to scenarios where datasets from different clients share the same feature space but differ in samples. In horizontal federated learning, each participating client has a dataset with the same features but different records. The main goal is to collaboratively train a global model without sharing the local data. This approach is beneficial when each client has a large number of unique samples. The workflow and algorithms explained so far are applicable with no change for horizontal FL.
2.2.3.2.2 Vertical Federated Learning (VFL)In vertical federated learning, each client has datasets containing different features but with the same sample IDs. The focus is on learning a combined model that utilizes all features from different datasets without sharing the raw data. The workflow and algorithms is provided below:1.Initialization: A global model is initialized. 2.Feature Alignment: Match the sample IDs across clients to align features. 3.Local Computation: Clients compute intermediate results based on their local features and send these to a central server or a coordinating client. 4.Model Aggregation: The server or coordinating client combines the intermediate results to update the model. FedSGD is a good candidate for vertical FL aggregation 5.Update Global Model: The model parameters are updated and shared back with clients. 6.Iteration: Steps 3–5 are repeated until the model converges. In a nutshell, the applications of Vertical Federated Learning include scenarios such as financial institutions where banks and insurance companies collaborate to build a credit scoring model using different types of data they possess about the same individuals, and cross-silo learning scenarios where different companies collaborate to enhance a model without revealing their proprietary data. In Vertical Federated Learning, the server’s role in aggregation involves combining intermediate results from different clients to update the global model. This process is more complex than in Horizontal Federated Learning due to the need to handle different features across the clients while maintaining the integrity of the sample alignment. Here’s a detailed explanation of how the server performs aggregation in Vertical Federated Learning:Feature alignment in Vertical Federated Learning involves two key aspects. Sample matching ensures that the samples across clients are aligned, with each sample uniquely identified, often through a common identifier such as a user ID. Feature distribution ensures that each client has a unique subset of features while sharing the same samples with other clients. In the local computation phase, clients compute partial gradients or intermediate values using their local features and the current model parameters. To maintain privacy, these computations are often performed using secure multiparty computation (MPC) techniques or homomorphic encryption to prevent the exposure of raw data.Intermediate results are then shared, where clients may encrypt their intermediate results before sending them to the server. These encrypted results are transmitted to the central server. At the server side, aggregation involves decryption (if needed), followed by combining the partial gradients or intermediate values from all clients. This step often includes summing the partial gradients or using weighted averaging, particularly if data distributions differ significantly. The combined gradients are then used to perform a step of gradient descent, updating the global model parameters.Model updates occur when the server updates the global model parameters using the aggregated gradients and distributes the updated parameters back to the clients. This iterative process, comprising local computation, intermediate result sharing, and aggregation, continues until the global model converges. For example, in a collaborative scenario, a bank and an insurance company might build a predictive model by combining their unique features while ensuring data privacy and security.
2.2.3.2.3 Federated Transfer Learning (FTL)Federated transfer learning addresses situations where datasets across clients have different samples and different features. It uses transfer learning techniques to adapt knowledge from one domain to another. The workflow and algorithms is provided below:1.Initialization: Initialize source and target models. 2.Knowledge Transfer: Use a pre-trained model on a related task (source domain) and adapt it to the target domain. 3.Local Training: Each client trains its part of the model on local data. 4.Transfer Learning: Apply transfer learning techniques to refine the model on the target data. 5.Model Aggregation: Aggregate updates from clients to refine the model iteratively. FTL can be applied in various scenarios where a pretrained model can be shared. For instance, consider scenarios where one client has rich, labeled data, and others have unlabeled or less representative data, benefiting from the rich data’s pre-trained models. And for a deeper understanding let’s delve into a collaborative healthcare system. In this scenario, the participants include a source client, which is a large hospital possessing extensive labeled medical imaging data and a pre-trained diagnostic model, and a target client, a smaller clinic with fewer labeled data points and different features such as patient demographics and symptoms. The workflow begins with the hospital’s robust diagnostic model, developed using a dataset with image-based features. The clinic, lacking sufficient data to train a high-performance model from scratch, has its own data, including demographics, symptoms, and a few labeled MRI scans. The hospital transfers its pre-trained model to the clinic, which fine-tunes it using its local data. The clinic adapts this model with its limited labeled MRI scans and additional features while the hospital continues to refine its model with its extensive dataset. Both entities share their updated model parameters securely with a central server to protect patient privacy. The central server aggregates these parameters, leveraging the hospital’s extensive imaging data and the clinic’s diverse feature set to create a generalized diagnostic model. The updated global model is then distributed back to both the hospital and the clinic. This process iterates, further refining the model through additional rounds of local adaptation and aggregation.
2.2.3.2.4 Hybrid Federated Learning (HFL)Hybrid Federated Learning combines elements of both Horizontal Federated Learning and Vertical Federated Learning. This approach is designed to handle scenarios where datasets across different clients may have overlapping features and samples as well as distinct features and samples. Hybrid Federated Learning aims to use the strengths of both horizontal and vertical data partitions to build more comprehensive and robust models. This type of Federated Learning is particularly suited for scenarios where there is overlap in samples and features among clients, as they may have datasets with some shared features and samples alongside unique ones. It is also ideal for cross-domain collaboration, where organizations from different fields, such as healthcare and finance, work together to develop a model that leverages data from both domains while ensuring sensitive information remains secure and private.The aggregation process in Hybrid Federated Learning involves several key steps. During the initial setup, each client has its own dataset, which may overlap with other clients in terms of samples and features, while a central server coordinates the training process and handles the aggregation of model updates. Clients begin by performing local computations on their datasets. For shared features, clients compute gradients or updates collaboratively, while for unique features, they perform computations tailored to their local data. Once computations are complete, clients generate intermediate results, such as gradients or weights, for both shared and unique features. These results are typically encrypted to maintain data privacy before being sent to the server. The server then aggregates updates for shared features across clients while handling unique feature updates separately, ensuring the global model benefits from all contributions without compromising privacy. Using the aggregated updates, the server updates the global model parameters and redistributes the updated model to all clients for further local training. This cycle of local computation, intermediate result sharing, and aggregation is repeated iteratively until the global model converges. To better understanding let’s review an example scenario in detail.Consider a scenario where a healthcare organization and a fitness app company collaborate to build a predictive model for health outcomes. The healthcare organization has medical records, while the fitness app company has activity data. Some individuals use both services, providing overlapping samples.In a hybrid federated learning scenario, the process begins with an initial setup involving two clients and a server. Client 1, a healthcare organization, holds medical records such as blood pressure and cholesterol levels, while Client 2, a fitness app company, possesses activity data like steps and heart rate. The server manages the global model and coordinates the aggregation of updates. During local computation, both clients train their models locally. For shared features, corresponding to overlapping individuals, they compute gradients or updates. For unique features—such as medical records for Client 1 and activity data for Client 2—they perform specific updates tailored to their datasets. Following local computation, both clients encrypt their intermediate results to preserve privacy and send the encrypted results to the server. The server decrypts these results, if necessary, and aggregates the updates for shared features. It processes updates for unique features separately to ensure that all contributions enhance the global model while maintaining data privacy. The server then updates the global model parameters using the aggregated updates and sends the updated model back to the clients. This process iterates through multiple rounds of computation, sharing, and aggregation until the global model achieves convergence.Federated learning enables collaborative model training while preserving data privacy across diverse scenarios through four main architectures. Horizontal Federated Learning addresses situations where clients have the same features but different samples, utilizing model updates aggregation by a central server. Vertical Federated Learning handles datasets with different features but the same samples by aligning features and combining partial gradients. Federated Transfer Learning applies transfer learning techniques to scenarios with different features and samples, transferring a pre-trained model from a source to a target client for local adaptation. Hybrid Federated Learning integrates both horizontal and vertical approaches to manage datasets with overlapping and unique features and samples, aggregating updates for both shared and unique data aspects. Each architecture ensures robust, secure, and privacy-preserving collaborative learning tailored to specific data distribution needs. For more detail read [10].



2.3 An Overview of Key Components of Federated Learning, Synchronization Strategies, and Coordination MechanismsThis subsection explores federated learning’s core components, including the interactions between clients, servers, and networks that enable collaborative machine learning while preserving data privacy and computational efficiency.2.3.1 Key Components of Federated LearningThrough federated learning, multiple decentralized entities, or clients, can collaborate to train machine learning models, while keeping the data local. Unlike traditional Machine Learning systems, which rely on a centralized architecture where data is collected, preprocessed, and used to train models on a central server before validation and deployment, federated learning maintains data privacy and security by ensuring that raw data does not leave the client’s location. This approach allows nodes in the distributed system to independently perform model training, using the strengths of centralized systems for data processing and model management. It capitalizes on distributed systems’ scalability, fault tolerance, and performance enhancements. To enable distributed machine learning while preserving data privacy and ensuring efficient model training, federated learning uses a sophisticated system of interconnected components. In this system, the Clients are the foundational elements of this system, typically comprising edge devices like smartphones, IoT devices, or specialized systems such as hospital networks. These clients maintain their own local datasets and perform computational tasks independently, which contributes to the overall data diversity of the learning process. The Central Server orchestrates the entire federated learning ecosystem. It initializes the global model, coordinates client activities, distributes training tasks, and aggregates updates from various clients. This is done to refine and improve the model continuously. A robust communication network connects these clients and the central server, managing secure data transfers and ensuring reliable information exchange. This network must be capable of handling high-volume data transmissions and frequent communications. The aggregator, typically integrated into the central server, consolidates model updates from different clients. Using advanced algorithms like Federated Averaging, it addresses the challenges of data heterogeneity and manages variations in client participation. Security Mechanisms are embedded to protect sensitive information, employing techniques like secure multi-party computation and differential privacy. These mechanisms ensure data integrity and prevent unauthorized access during model aggregation. The Model Validation Module evaluates the performance of the aggregated model against predefined standards, utilizing centralized or distributed validation datasets to fine-tune and assess model effectiveness. Lastly, the Data Management Layer handles crucial logistical aspects such as metadata management, client availability tracking, and resource scheduling. This component ensures smooth coordination and efficient task distribution across the distributed network. As shown in Table 2.3, these components work together to enable collaborative machine learning while maintaining data privacy and security [11].Table 2.3Components enabling collaborative machine learningKey componentsDescriptionKey functionsClientsTypically edge devices or local servers that hold data relevant to the federated learning task, such as smartphones, IoT devices, or hospital systems. They perform computations locally and maintain their own datasets, contributing to data diversity.Maintains own datasetPerforms local computationsCentral serverActs as the orchestrator of the federated learning process, coordinating clients, distributing tasks, and aggregating updates. It sends the initial global model to clients and collects updates post-training to refine the global model.Model initializationClient coordinationTask distributionAggregation of updatesCommunication networkConnects clients with the central server, handling data transfers and ensuring secure communication. This network must be robust to manage high volumes of data and frequent communications.Manages data transfersEnsures secure communicationAggregatorUsually part of the central server, it aggregates model updates from clients using algorithms like Federated Averaging (FedAvg). This component is crucial for addressing data heterogeneity and skewed client participation.Aggregates model updatesOptimizes the global modelSecurity mechanismsEquipped with advanced security features such as secure multi-party computation (SMPC) and differential privacy to protect client data during aggregation and ensure the integrity of the federated learning process.Protects client dataEnsures system integrityModel validation moduleEvaluates the performance of the aggregated model against predefined standards and objectives. It may utilize validation datasets that are centrally held or distributed across clients participating in validation rounds.Evaluates model performanceFine-tunes the modelData management layerHandles metadata, client availability, data distributions, and other logistical aspects of the federated learning system. This component supports the smooth and efficient management of resources and scheduling of tasks across the distributed network.Manages metadata and logisticsSupports resource and task scheduling
2.3.2 Synchronization Strategies for Federated LearningAs discussed throughout the chapter, the central idea of federated learning revolves around aggregating collected model updates. Synchronization strategies in federated learning refer to the various methods used to coordinate and integrate these local updates into the global model. Given the challenges of communication, computation, and privacy, synchronization strategies play a crucial role in determining the efficiency, performance, and privacy of the system. Depending on whether the clients synchronize in each round or not, these strategies are categorized into synchronous scenarios, asynchronous scenarios, hybrid strategies, and hierarchical synchronization [11, 12].2.3.2.1 Centralized SynchronizationCentralized synchronization is a strategy where a central server manages model update coordination. This process operates in rounds: the server sends the current global model to a subset of clients, who train it with their local data. After training, the clients send their updates back to the server, which aggregates them, typically using Federated Averaging, to create a new global model. This cycle continues until a certain number of rounds are completed or a convergence condition is achieved. The main advantages of this approach are its simplicity, central control, and predictable communication patterns. However, it also has drawbacks, such as scalability limitations, potential communication bottlenecks, and a single point of failure.
2.3.2.2 Asynchronous SynchronizationAsynchronous synchronization allows clients to send updates to a central server independently, without waiting for other clients or the completion of a global round. This strategy features flexible communication, as clients can upload their updates whenever they are ready. The server integrates them into the global model upon receipt. This reduces idle time, allowing users to work at their own pace. Asynchronous synchronization offers greater flexibility, reduced synchronization delays, and improved scalability. However, it also has potential downsides, such as model inconsistency and the need for more complex aggregation techniques to manage asynchronous updates. It is even possible to have multiple zones of synchrony where separate aggregators control client synchronization. This approach is known as hierarchical synchronization.
2.3.2.3 Hierarchical SynchronizationHierarchical synchronization in federated learning involves a multi-tiered coordination system. This strategy typically divides clients into groups or regions, with each group having its own aggregator. These groups perform local aggregation before sending results to a central server for further processing. This approach reduces communication overhead, improving scalability and allowing localized learning. However, hierarchical synchronization has its challenges, including increased complexity and the need for careful design to maintain consistency across different groups.
2.3.2.4 Hybrid SynchronizationHybrid synchronization strategies aim to balance the benefits of both synchronous and asynchronous modes. In this approach, clients are divided into groups based on their computational power, network latency, or other factors. High-capacity clients might operate synchronously within their group, while lower-capacity clients work asynchronously. This strategy can improve resource utilization while maintaining a reasonable level of global consistency. However, hybrid models introduce complexities in aggregation and coordination that need to be managed, particularly when reconciling updates from asynchronous clients with synchronous rounds.
2.3.2.5 Adaptive SynchronizationAdaptive synchronization dynamically adjusts the coordination strategy based on system conditions such as network bandwidth, client availability, or computational load. For example, during periods of high network congestion, the system may switch from synchronous to asynchronous updates. Conversely, if client updates are highly inconsistent, the system can enforce synchronization to align model parameters more closely. This dynamic adaptability enhances the resilience of federated learning systems, particularly in heterogeneous and volatile environments, making it well-suited for real-world deployments.
2.3.2.6 Security and Robustness in SynchronizationSynchronization strategies also play a critical role in ensuring federated learning security and robustness. For instance, asynchronous updates can introduce vulnerabilities, such as model poisoning attacks, where delayed or malicious updates corrupt the global model. Strategies like robust aggregation algorithms, Byzantine fault tolerance, or differential privacy can mitigate these risks. Furthermore, hierarchical synchronization can help localize the impact of such attacks to smaller groups, reducing widespread disruption.
2.3.2.7 Edge-Based SynchronizationEdge-based synchronization leverages edge servers as intermediate aggregators between clients and the central server. These edge servers collect updates from nearby clients, perform localized aggregation, and send the results to the central server. This approach reduces communication latency, alleviates server-side bottlenecks, and is particularly effective in applications like IoT systems and smart cities. However, ensuring consistency across different edge servers requires robust mechanisms, especially when dealing with updates from resource-constrained clients.Table 2.4 summarizes the key synchronization strategies discussed in this section, highlighting their defining features, advantages, and challenges.Table 2.4Summarization of synchronization strategiesSynchronization strategyDescriptionAdvantagesChallengesCentralized synchronizationA central server coordinates model updates in rounds.Simplicity, central control, predictable communication patterns.Scalability limitations, communication bottlenecks, single point of failure.Asynchronous synchronizationClients independently send updates to the server without waiting for others.Greater flexibility, reduced synchronization delays, improved scalability.Model inconsistency, complex aggregation techniques needed for asynchronous updates.Hierarchical synchronizationMulti-tiered system where groups of clients perform local aggregation before sending results to a central server.Reduces communication overhead, improves scalability, allows localized learning.Increased complexity, requires careful consistency design across groups.Hybrid synchronizationCombines synchronous and asynchronous strategies for different client groups based on their characteristics.Balances resource utilization, maintains global consistency.Complex coordination and aggregation, reconciliation challenges.Adaptive synchronizationDynamically adjusts synchronization strategy based on system conditions.Enhances resilience in heterogeneous environments, flexible for real-world use.Requires dynamic monitoring and strategy adjustment mechanisms.Security and robustnessIncorporates mechanisms like robust aggregation and differential privacy to ensure security.Mitigates risks like poisoning attacks, reduces disruption scope.Additional computational and algorithmic complexity.Edge-based synchronizationUses edge servers as intermediate aggregators to collect updates and reduce central server load.Lowers latency, alleviates bottlenecks, effective in IoT and smart cities.Consistency issues across edge servers, challenges with resource-constrained clients.


2.4 Federated Learning Challenges and SolutionsThis section explores the critical challenges in federated learning and presents strategies to address them effectively.2.4.1 ChallengesThis section examines some of the most critical challenges facing federated learning [13].2.4.1.1 Data HeterogeneityData heterogeneity in federated learning refers to the scenario where data across different clients vary widely in terms of volume, distribution, and underlying characteristics. This variability can lead to a model that performs well on data from some clients but poorly on others.
2.4.1.2 Skewed Client ParticipationSkewed client participation occurs when certain clients are more frequently selected or able to participate in the training rounds than others, which can bias the model towards the data characteristics of these clients.
2.4.1.3 Communication Challenges in Federated LearningWhile federated learning has been successful in alleviating the strain on communication infrastructure by bringing the code to the data, it is not without its challenges. One of the primary issues arises from the increasing number of end users attempting to update the central server, which can create bottlenecks, particularly when the clients have significantly weaker connections compared to the data center network. Furthermore, ensuring security, integrity, and robustness is paramount.Given the outlook that federated learning has drawn regarding computational scalability and privacy protection for machine learning applications, especially in the area of edge computing and the Internet of Things, it’s not hard to predict an increase in the number of clients. In order to keep the pace, handling the challenges this increase would cause is mandatory.Although the possibility of keeping data preserved at their production location by favor of FL, reduces the communication cost profoundly, still there are some overheads that can be annoying especially in the presence of a very high amount of clients. In order to efficiently model convergence by aggregator, several rounds of model update must be run. Following challenges force the aggregator to lengthen each round or increase the needed round. In each case the communication rises and the training phase would take longer.2.4.1.3.1 Uneven Distribution of Data among ClientsIn Federated Learning, there’s no guarantee that data from different clients will be evenly distributed or share the same characteristics. This phenomenon, known as “non-independently and identically distributed data” or Non-IID, is common in real-world situations. It means that data from various clients (devices) might not follow the same distribution or could be interdependent due to unique behaviors and environments. This variability is a significant challenge in Federated Learning, as each client contributes data influenced by their specific context. Non-IID data contributes to communication costs in Federated Learning in several ways. The ways include increased model updates, frequent synchronization, slower convergence speed, and data skewness.Increased model updates occur because each client, having a unique data distribution, will likely produce a distinct model update during training. The server needs to aggregate updates from all clients, leading to increased communication. To address these updates, synchronization is often needed. Frequent synchronization becomes necessary because the model parameters can diverge significantly across clients due to the non-IID nature of the data. To prevent this, more frequent communication between the server and clients is required, increasing the communication cost. It should be noted that convergence speed is also impacted. Non-IID data can slow down the convergence of the model, requiring more communication rounds to reach the desired accuracy. In addition to convergence challenges, data skewness emerges as a critical issue. Some classes of data may be over-represented in some clients and under-represented in others in non-IID settings. This imbalance can lead to poor model performance, requiring additional communication to correct.
2.4.1.3.2 Variability in Clients ConnectionsThis issue arises in cellular networks where devices connect with varying signal strengths due to their geographical locations and environmental conditions. Devices with poor connectivity can hinder the training process by slowing it down.


2.4.2 SolutionsThis section examines some solutions provided for critical challenges outlined in this section.2.4.2.1 Solutions for Data Heterogeneity and Skewed Client ParticipationAs mentioned earlier, a well-designed aggregator is crucial in addressing two significant challenges in federated learning: heterogeneous data across clients and skewed client participation.2.4.2.1.1 Strategies to Mitigate Data HeterogeneityData heterogeneity can be mitigated with advanced aggregation algorithms, client clustering, and robust statistical methods [14].1.Advanced Aggregation Algorithms: Federated Averaging (FedAvg), which is specially designed to handle independently and identically distributed non-IID data, can provide assistance. The algorithms normalize the influence of diverse data sets by weighing the contributions of each client according to the quality or quantity of their data. 2.Client Clustering: Grouping clients with similar data characteristics together before aggregation can also mitigate heterogeneity. Within these clusters, models are trained locally on more homogeneous data, and the results are aggregated separately before a final global aggregation. 3.Robust Statistical Techniques: Applying techniques like outlier detection to discard or reweight updates that are too far from the mean or median can prevent extreme values from skewing the model. Table 2.5 summarizes mentioned strategies to mitigate data heterogeneity.Table 2.5Strategies to mitigate data heterogeneityStrategyDescriptionBenefitAdvanced aggregation algorithmsAlgorithms that weight client updates differently based on data characteristicsEnsures fair representation in the global modelClient clusteringGrouping similar clients for localized aggregationReduces the impact of data variabilityRobust statistical techniquesTechniques to handle outliers in data updatesPrevents extreme data from skewing results
2.4.2.1.2 Strategies to Mitigate Skewed Client ParticipationIn order to mitigate skewed client participation, incentive mechanisms are used as well as periodic rebalancing in order to select more fair clients [14].1.Fair Client Selection: Implementing a fair client selection protocol that ensures all clients have equal chances of participation over time. This can include mechanisms to track participation history and adjust probabilities accordingly. 2.Incentive Mechanisms: Providing incentives for underrepresented clients to participate can balance the participation rates across the network. 3.Periodic Rebalancing: Periodically adjusting the model to account for underrepresented client data by either boosting their model updates or explicitly promoting their participation. Table 2.6 summarizes mentioned strategies to mitigate skewed client participation.Table 2.6Strategies to mitigate skewed client participationStrategyDescriptionBenefitFair client selectionA selection protocol that ensures equal participation opportunitiesReduces bias in model trainingIncentive mechanismsIncentives for increased participation from underrepresented clientsBalances the training data poolPeriodic rebalancingAdjustments to include underrepresented dataEnhances model fairness and accuracy
2.4.2.1.3 Strategies for Mitigating Communication ProblemsTo tackle this challenge, two main approaches are used: reducing the size of the update model and carefully selecting which clients participate in the training process. Reducing the size of the update model in federated learning involves strategies to minimize the data transferred from individual clients to the central server during model training, and for reduction, there are three common ways which are quantization, sparsification, and gradient compression.Quantization reduces the precision of model parameters by converting them to lower-bit representations. By using fewer bits to represent each parameter, quantization reduces the amount of data transferred without severely impacting model performance. Developing aggregation techniques that are resilient to the impacts of quantization is an emerging area of research. Sparsification involves transmitting only a subset of the most significant parameters, specifically those with the largest changes. This strategy significantly reduces data volume by focusing on the most impactful updates. In this context, adaptive sparsification is a recognized practice, requiring an automatic trade-off between efficient communication and the model’s optimality. Gradient compression, similar to sparsification, compresses the gradients (the derivative of the loss function with respect to model parameters) before sending them to the central server. This may involve thresholding (sending only gradients above a certain value) or using more efficient encoding techniques to reduce data size.It should be noted that references [15, 16] can be a great help for deeper understanding of model reduction techniques.In Federated Learning, clients, like smartphones, IoT devices, or computers, work together to train a shared model, but each client has varying connectivity and resources. Client selection in Federated Learning is a strategy used to manage the impact of connection variability among clients. One effective approach is importance-based selection, where clients are chosen based on their contribution to the model’s learning process, prioritizing those with high-quality, diverse data. Resource-aware selection focuses on clients with sufficient bandwidth and battery life, reducing interruptions and inefficiencies caused by resource constraints. Randomized selection ensures fairness and prevents overfitting by selecting clients randomly, although it may not always optimize communication efficiency.Cluster-based selection groups clients based on attributes such as geographic proximity or data similarity, balancing the communication load and ensuring diverse data representation. Adaptive selection dynamically adjusts the client selection strategy based on real-time network conditions and client behavior, optimizing communication efficiency and robustness. Quota-based selection assigns participation quotas to clients, distributing the communication load evenly and ensuring sustainable client engagement over time.Performance-based selection favors clients with higher computational power and consistent performance, enhancing overall training efficiency. Proximity-based selection reduces latency by choosing clients closer in physical or network proximity, improving communication efficiency and reducing data transfer issues. By employing these client selection techniques, federated learning systems can address communication challenges, leading to more efficient and effective distributed model training. Following table summarizes these strategies (Table 2.7):Table 2.7Strategies for mitigating communication problemsClassStrategiesDescriptionReductionQuantizationReduces the precision of model parameters, converting them to lower-bit representations to minimize data transferred. Aggregation techniques resilient to quantization impacts are being researched.SparsificationTransmits only a subset of significant parameters, reducing data volume by focusing on the most impactful updates. Adaptive sparsification establishes a trade-off between communication efficiency and model optimality.Gradient compressionCompresses gradients before sending to the central server, using techniques like thresholding or efficient encoding to reduce data size.SelectionImportance-based selectionSelects clients based on their data’s contribution to the model’s learning process, prioritizing high-quality, diverse data.Resource-aware selectionFocuses on clients with sufficient bandwidth and battery life to reduce interruptions and inefficiencies.Randomized selectionEnsures fairness and prevents overfitting by selecting clients randomly, though it may not optimize communication efficiency.Cluster-based selectionGroups clients based on attributes like geographic proximity or data similarity, balancing communication load and ensuring diverse data representation.Adaptive selectionDynamically adjusts client selection strategy based on real-time network conditions and client behavior, optimizing communication efficiency and robustness.Quota-based selectionAssigns participation quotas to clients, distributing communication load evenly and ensuring sustainable client engagement over time.Performance-based selectionFavors clients with higher computational power and consistent performance, enhancing overall training efficiency.Proximity-based selectionReduces latency by choosing clients closer in physical or network proximity, improving communication efficiency and reducing data transfer issues.



2.5 Federated Learning Threats and SolutionsThis section explores the security risks associated with federated learning and strategies to mitigate them for better robustness and privacy assurance.2.5.1 Security and Privacy ThreatsThis subsection elaborates on security and privacy threats related to federated learning.2.5.1.1 Data LeakageGiven that Federated Learning involves sharing model updates while keeping client data on local devices, robust protocols are needed to protect sensitive information and facilitate secure communication.In Federated Learning, clients compute local gradients based on their data and share them with a central server to update a global model. However, even though the raw data remains on the clients, gradients can still leak information about the data’s characteristics, allowing adversaries to make inferences about individual users or groups.Attackers could analyze gradients to deduce specific data points, compromising user privacy. For example, by observing patterns in the gradients, attackers might infer personal information like location, health status, or even specific records [17].
2.5.1.2 Membership Inference AttacksIn this type of attack, adversaries determine whether specific data is part of the dataset used to train the model. This can lead to significant privacy concerns, as it may reveal sensitive information about individuals or groups [17].
2.5.1.3 Model Inversion AttacksAttackers use gradients to reconstruct input data or infer attributes of the underlying dataset. This can be a severe privacy threat, allowing adversaries to reverse-engineer private information from the gradients [17].
2.5.1.4 Adversarial AttacksMalicious clients can inject corrupted gradients to manipulate the learning process. This can lead to model poisoning, where the entire model is compromised, affecting its performance and accuracy [17].

2.5.2 Solution of ThreatsTo mitigate these risks, Federated Learning systems must incorporate robust security and privacy measures, including:2.5.2.1 Secure AggregationTechniques that allow the central server to aggregate gradients without learning individual contributions help reduce the risk of data leakage. It means the data can be processed while it remains ciphered. One of the key tools for this kind of computing is homomorphic encryption. This technique enables computations on encrypted data, allowing gradients to be shared without exposing their content. That’s where the terms “homomorphic” come from; the relationship between the transformed data is just exactly the same as the original one [17].
2.5.2.2 Differential PrivacyAdding controlled noise to gradients can obscure specific data points, enhancing privacy and reducing the impact of membership inference attacks. Differential privacy introduces a privacy budget, which represents the level of privacy in a system, with smaller budgets indicating higher privacy. It can be implemented through noise injection, gradient clipping, and secure aggregation, balancing privacy with model utility. However, challenges include balancing privacy with model accuracy and managing computational complexity. Despite these challenges, differential privacy is a fundamental method for ensuring privacy in Federated Learning [17].
2.5.2.3 Robustness to Adversarial AttacksImplementing checks and validations to ensure that malicious gradients don’t compromise the model. This might include outlier detection or secure protocols for model updates. Robust optimization and Byzantine-Resilient Algorithms are key techniques to secure model aggregation against malicious updates by adversaries.. Robust optimization focuses on maintaining stable and reliable model performance despite variability in data or parameters. It involves techniques like uncertainty sets, regularization, and stochastic optimization to create models that can adapt to changing conditions without degrading in performance. Byzantine-resilient algorithms, on the other hand, are designed to withstand attacks from malicious clients, known as Byzantine faults. These algorithms aim to ensure the integrity of the learning process even when some clients submit corrupted or malicious data. Byzantine-resilient algorithms typically include mechanisms for secure aggregation, anomaly detection, and robust consensus to prevent malicious inputs from compromising the model’s accuracy or security [17].


2.6 Federated Learning TerminologyFor clarity, precision, and standardization of concepts within the federated learning concept, the following section provides terminology of federated learning.2.6.1 Underrepresented ClientsIn the context of federated learning, “Underrepresented Clients” refers to participants in the network whose data or contributions are not as frequently included or considered in the model training process as others. This underrepresentation can occur due to various reasons, such as less frequent selection for training rounds, lower data volume, or data that is significantly different from the majority of participants. Underrepresentation can lead to biases in the model, as it may not learn well from the diverse data scenarios it will encounter in actual use. Similar phrases and terms include: minority clients, which emphasizes that these clients are in the minority in terms of data contribution or selection frequency; infrequently selected clients, explicitly referring to the selection mechanism that leads to fewer opportunities for some clients to participate; marginalized clients, often used in socio-political contexts, describing clients whose data contributions are given less importance in the aggregation process; less active clients, referring to clients that either opt to participate less frequently or are chosen less often due to the nature of their data or network constraints; and peripheral clients, suggesting these clients are on the periphery of the main activity in the federated learning system, not central to the model updates.
2.6.2 Non-independent and Identically DistributedIn federated learning, each client’s data may have unique characteristics—for example, different underlying distributions, varying degrees of label imbalance, or domain-specific patterns—leading to what is known as Non-Independent and Identically Distributed data. Unlike a traditional, centralized training scenario where data can be shuffled or balanced to achieve a more uniform distribution, federated learning must respect each client’s local data constraints. This inherent heterogeneity means that the data from one client may not only be unrepresentative of another client’s data, but may also differ significantly in terms of features, data quantity, and underlying statistical properties. As a result, training a robust global model becomes more challenging, since strategies that assume homogeneous data distributions often fail to generalize well across clients with varying data characteristics. Effectively addressing these non-IID conditions often requires specialized aggregation rules, personalization techniques, and sophisticated model architectures capable of accommodating and leveraging the diversity of client data.
2.6.3 AggregatorIn federated learning, the Aggregator, often a central coordinating entity such as a server or distributed service, orchestrates the iterative process of model training. Its primary functions include collecting local updates, integrating updates, and distributing the global model.The aggregator collects model updates, such as weight parameters, gradients, or other attributes, from participating clients after each round of local training. These updates encapsulate the learned patterns from the clients’ local datasets. Next, the aggregater integrates these updates using strategies that range from simple averaging to advanced methods. These strategies might weigh updates based on factors like client reliability, data quality, or model divergence, merging the updates into a single, improved global model.Once the new global model is created, the Aggregator distributes it back to the clients for the next round of local training, ensuring that all participants access the most up-to-date, collectively learned model parameters. By managing this flow of information and continually refining the global model, the Aggregator supports privacy-preserving federated learning by achieving a collective model without accessing any individual client’s raw data.

2.7 SummaryIn the chapter Core Concepts of Federated Learning, we explored the foundational elements that underpin federated learning systems. The discussion began with an examination of the Key Components of Federated Learning Systems. It highlighted essential elements such as clients, servers, local models, and the global aggregation process. These components form the backbone of any federated learning system, ensuring decentralized learning while preserving data privacy.Next, we provided An Overview of Key Components of Federated Learning. This chapter detailed synchronization strategies and coordination mechanisms that are vital for maintaining efficiency and coherence in distributed learning environments. This section emphasized the importance of communication protocols, model update timing, and client-server collaboration in ensuring successful federated learning operations.The chapter also addressed Federated Learning Challenges and Solutions, focusing on common issues such as data heterogeneity, communication overhead, and system scalability. Proposed solutions included adaptive learning rates, client selection techniques, and model compression methods to tackle these challenges effectively.Finally, this chapter discussed Federated Learning Threats and Solutions, examining potential security and privacy risks, such as data leakage, model poisoning, and adversarial attacks. Countermeasures like secure multiparty computation, differential privacy, and robust aggregation techniques were presented to mitigate these threats.Through this chapter, readers gain a comprehensive understanding of the core concepts, challenges, and solutions integral to federated learning. This lays the groundwork for its application in diverse domains.
2.8 ConclusionThis chapter encapsulates the essential aspects of federated learning by highlighting the relationship between its key components and workflow. It also illustrates the innovative approach to data collaboration. It emphasizes the pivotal role of federated algorithms in efficient and scalable training. This chapter sheds light on the critical threats to federated systems and the necessity of robust security mechanisms to ensure their integrity and privacy. As a result, these insights provide a solid foundation for advancing distributed learning research and implementation.
References1.Beltrán, E. T. M., Pérez, M. Q., Sánchez, P. M. S., Bernal, S. L., Bovet, G., Pérez, M. G., et al. (2023). Decentralized federated learning: Fundamentals, state of the art, frameworks, trends, and challenges. IEEE Communications Surveys & Tutorials.
2.Banabilah, S., Aloqaily, M., Alsayed, E., Malik, N., & Jararweh, Y. (2022). Federated learning review: Fundamentals, enabling technologies, and future applications. Information Processing & Management, 59(6), 103061.Crossref
3.Agrawal, S., Sarkar, S., Aouedi, O., Yenduri, G., Piamrat, K., Alazab, M., et al. (2022). Federated learning for intrusion detection system: Concepts, challenges and future directions. Computer Communications, 195, 346–361.Crossref
4.Blanco-Justicia, A., Domingo-Ferrer, J., Martínez, S., Sánchez, D., Flanagan, A., & Tan, K. E. (2021). Achieving security and privacy in federated learning systems: Survey, research challenges and future directions. Engineering Applications of Artificial Intelligence, 106, 104468.Crossref
5.Mothukuri, V., Parizi, R. M., Pouriyeh, S., Huang, Y., Dehghantanha, A., & Srivastava, G. (2021). A survey on security and privacy of federated learning. Future Generation Computer Systems, 115, 619–640.Crossref
6.McMahan, B., Moore, E., Ramage, D., Hampson, S., & y Arcas, B. A. (2017, April). Communication-efficient learning of deep networks from decentralized data. In Artificial intelligence and statistics (pp. 1273–1282). PMLR.
7.Zhu, H., Xu, J., Liu, S., & Jin, Y. (2021). Federated learning on non-IID data: A survey. Neurocomputing, 465, 371–390.Crossref
8.Li, T., Sahu, A. K., Zaheer, M., Sanjabi, M., Talwalkar, A., & Smith, V. (2020). Federated optimization in heterogeneous networks. Proceedings of Machine Learning and Systems, 2, 429–
