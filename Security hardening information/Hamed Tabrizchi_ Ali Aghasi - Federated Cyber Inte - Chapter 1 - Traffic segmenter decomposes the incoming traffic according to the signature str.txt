# Security Chapter Extract
Book: Hamed Tabrizchi_ Ali Aghasi - Federated Cyber Intelligence _ Federated Learning for Cybersecurity (2025, Springer Nature Switzerland) - libgen.li
Chapter: 1 - Traffic segmenter decomposes the incoming traffic according to the signature structure. Signatures basically designed considering known attacks patterns. Thus signature-based IDSs have been vulnerable to zero-day attacks [8].Diagram illustrating a traffic analysis process. Input traffic enters a "Traffic Segmenter," which directs it through a series of "Signatures" labeled from #1 to #n. If a match is found, a "Matching Alert" is triggered. The processed data exits as output traffic.Fig. 4.1Signature stack in a traditional IDSBecause of their reliance on predetermined and well-defined samples, they can achieve a high level of accuracy and low false positive rate. The deployment of such a system is easy, but it requires frequent updates to cope with new threats. As the stack of signatures grows, the system’s speed could be affected. Modern persistent threats urge the need for sophisticated methods that can inspect the threats behaviorally and are capable of detecting anomalies of incoming traffic. Such techniques rely on artificial intelligence concepts in general and focus on machine learning methods in particular. Therefore the main research direction of IDS development has been focused on adopting different machine learning methods [9]. Using historical data, ML methods can classify and predict incoming events and strengthen the decision making process by extracting meaningful insights without being explicitly programmed.
Security Relevance Score: 20
Word Count: 3906
Extracted: 2025-06-13 23:40:53

---

Traffic segmenter decomposes the incoming traffic according to the signature structure. Signatures basically designed considering known attacks patterns. Thus signature-based IDSs have been vulnerable to zero-day attacks [8].Diagram illustrating a traffic analysis process. Input traffic enters a "Traffic Segmenter," which directs it through a series of "Signatures" labeled from #1 to #n. If a match is found, a "Matching Alert" is triggered. The processed data exits as output traffic.Fig. 4.1Signature stack in a traditional IDSBecause of their reliance on predetermined and well-defined samples, they can achieve a high level of accuracy and low false positive rate. The deployment of such a system is easy, but it requires frequent updates to cope with new threats. As the stack of signatures grows, the system’s speed could be affected. Modern persistent threats urge the need for sophisticated methods that can inspect the threats behaviorally and are capable of detecting anomalies of incoming traffic. Such techniques rely on artificial intelligence concepts in general and focus on machine learning methods in particular. Therefore the main research direction of IDS development has been focused on adopting different machine learning methods [9]. Using historical data, ML methods can classify and predict incoming events and strengthen the decision making process by extracting meaningful insights without being explicitly programmed.
4.2.1.2 ImplementationAny ML-based system needs data for the model to be trained on. A stand alone IDS system relying on its own data samples gathered through its past operations not knowing what may happen on other systems may raise the risk of being compromised by attacks other organisations faced before. A wiser option is involving a more comprehensive model training on data from various endpoints and using. As we know from previous chapters, these systems can generally be implemented either based on a central repository where all the data piled up in a central repository or based on a more sophisticated approach called federated learning. Figure 4.2 shows an illustration of the first scenario that is grounded on a central learning of traffic patterns from distributed traffic sources. Despite the benefits, network data often includes sensitive information that can expose risks, such as user browsing histories, the applications they interact with, and vital endpoint information like domain controllers and firewalls. As a result, implementing a centralized learning approach can introduce significant privacy, security, and transactional vulnerabilities that organizations typically aim to mitigate or prevent. Such risks could lead to potential breaches of confidentiality and integrity, prompting many organizations to reconsider or avoid centralized data management strategies altogether [6].Diagram illustrating a data flow process for a machine learning-based intrusion detection system (ML-Based IDS). Arrows represent traffic moving into local data storage units, which then consolidate into a central repository. The central repository connects to gears symbolizing the ML-Based IDS. Labels include "traffic," "Local Data," "Central Repository," and "ML-Based IDS."Fig. 4.2Centralized ML IDSIn a federated IDS, each node or endpoint like a company’s network trains a local model on its own data. Periodically, these local models are aggregated to form a global model that benefits from the collective knowledge of all nodes. This approach maintains data privacy and leverages diverse datasets to improve detection accuracy. The concept is depicted in Fig. 4.3.Diagram illustrating a network system with three Local IDS components, each represented by a cylinder and gears, connected to a central Aggregator, depicted as a circle with arrows. Black arrows indicate data flow from Local IDS to the Aggregator, while red arrows show data distribution from the Aggregator back to the Local IDS. A legend on the right labels the symbols for Aggregator and Local IDS.Fig. 4.3General architecture of an FL based IDs
4.2.1.3 BenefitsPrivacy Preservation: Local data never leaves the node, reducing the risk of data breaches. This ensures compliance with privacy regulations and minimizes the risk of sensitive data exposure.Improved Detection: The global model benefits from diverse datasets, enhancing its ability to detect a wide range of threats. By incorporating data from multiple sources, the model can identify patterns and anomalies that may not be apparent in a single dataset.Scalability: The decentralized nature of FL allows IDS to scale across multiple nodes efficiently. Each node processes its own data, reducing the computational burden on central servers and enabling real-time analysis.

4.2.2 Federated Learning for Malware DetectionMalware detection systems play a vital role in safeguarding digital infrastructure by identifying and mitigating malicious software that can compromise systems and data. Traditional malware detection methods often rely on centralized machine learning models, which require the collection and aggregation of malware samples from various sources. This approach raises significant privacy concerns and may limit the diversity of data used for training, reducing the model’s ability to detect novel or advanced malware. FL addresses these challenges by enabling decentralized collaboration among organizations to train malware detection models without sharing sensitive data. Through FL, diverse malware datasets from different environments—such as enterprise systems, cloud platforms, and IoT devices—can collectively contribute to a robust and adaptive global model [10]. This approach not only enhances the detection of emerging malware variants but also ensures compliance with data protection regulations, fostering a secure and privacy-preserving framework for malware defense.4.2.2.1 OverviewBefore the adoption of ML techniques, traditional malware detection relied primarily on signature-based and heuristic methods. Signature-based detection involves identifying malware by comparing code against a database of known malware signatures—unique strings of data or code patterns associated with malicious software [11]. These methods, while effective for known threats, have several significant limitations. The primary drawback is their inability to detect new or evolving malware, often called zero-day threats, which lack an existing signature. Signature-based systems require regular updates to their databases to keep up with the rapidly evolving threat landscape, leading to periods where newly discovered malware can evade detection.To improve upon this, heuristic-based methods were developed, which attempt to identify malware based on its behavior rather than a specific signature. These systems monitor files and programs for suspicious activity, such as attempts to modify core system files or initiate unauthorized network connections [11]. However, heuristic methods can be prone to false positives, where benign software is incorrectly flagged as malicious. This creates a trade-off between sensitivity and accuracy, as highly sensitive systems may generate too many alerts, while more conservative systems risk missing actual threats [12].While both signature and heuristic-based approaches laid the foundation for malware detection, they struggled with scalability, adaptability, and the increasing complexity of modern malware. The rapid evolution of malware strains, the sheer volume of data to analyze, and the need for real-time protection highlighted the limitations of these traditional methods. The growing sophistication of malware, including polymorphic malware that can modify its code to evade detection, created a pressing need for more intelligent, adaptable solutions.
4.2.2.2 Machine Learning for Malware Detection: Motivation and ChallengesThe emergence of machine learning provided a promising new avenue for malware detection. ML algorithms can automatically learn patterns from vast datasets, enabling systems to detect previously unseen malware by identifying malicious behaviors, data patterns, or anomalies without relying on predefined signatures. This allows ML models to generalize and detect zero-day threats, making them more versatile than traditional methods. Additionally, machine learning can analyze vast amounts of data quickly, providing scalable solutions capable of handling the enormous datasets that modern cyber security systems must process.Machine learning-based malware detection systems are typically trained on historical data, where labeled datasets of malware and benign software are used to teach the model to distinguish between malicious and non-malicious behavior. These models can analyze various features, such as file structure, execution behavior, network traffic patterns, and system calls, enabling more accurate and comprehensive detection [13].However, despite the advantages, traditional machine learning models also face several challenges that limit their effectiveness. One of the most pressing challenges is data privacy. To train an effective ML model, a vast amount of data from various devices and environments is required, often involving sensitive or proprietary information. This raises privacy concerns, particularly in industries such as healthcare and finance, where data protection regulations are stringent. Centralizing all this data in one location for model training makes it vulnerable to breaches or misuse, which is a significant drawback.Another challenge is scalability. As the volume of data continues to grow, centralized machine learning models become difficult to manage. Collecting, storing, and processing large datasets from multiple devices requires significant computational resources and infrastructure. Furthermore, transferring data from individual devices to a central server introduces latency, which is particularly problematic in systems that require real-time detection, such as malware detection on edge or IoT devices [14].A further limitation is adaptability. Cyber threats evolve rapidly, and malware is becoming increasingly sophisticated. Traditional machine learning models often struggle to keep up with these evolving threats because they require periodic retraining and updating. This process can be slow and resource-intensive, leaving systems vulnerable to new forms of malware during the intervals between updates. Furthermore, the central model may not be able to incorporate local-specific threats that individual devices or environments encounter, making it less effective in certain contexts.These challenges create a strong motivation for the adoption of federated learning in malware detection systems. Federated learning offers a decentralized approach that addresses the privacy, scalability, and adaptability issues associated with traditional ML-based solutions. Instead of sending all data to a central server for training, FL enables individual devices to train local models using their own data. The insights from these local models are then aggregated to form a global model, without any raw data ever leaving the device. This approach preserves data privacy, reduces the need for massive data transfers, and allows for more frequent updates to the global model, ensuring that it remains adaptable to new malware threats.Federated learning, therefore, offers a balanced solution to the limitations of traditional malware detection methods, providing the scalability, real-time adaptability, and privacy protection that modern cyber security systems require.
4.2.2.3 ImplementationImplementing a federated learning based malware detection system involves several key steps, processes, and considerations to ensure the system is both effective in detecting malware and efficient in preserving privacy. This section delves into the implementation of such a system, using detailed examples and simulated data to illustrate how federated learning can improve malware detection.4.2.2.3.1 Architecture of Federated Learning-Based Malware DetectionAt a high level, a federated learning malware detection system consists of several devices (clients), such as personal computers, smartphones, or IoT devices, which each train a local model on their data. These devices communicate with a central server, which aggregates the locally trained models into a global model. The key feature of this system is that no raw data leaves the devices, preserving privacy while still leveraging the collective intelligence from a wide range of environments.Each device collects and labels data on detected malware or malicious behaviour. These data points could include information on suspicious file behaviours, unusual network traffic, or deviations in software execution patterns. Once a sufficient amount of local data has been accumulated, the device trains a local machine learning model, which learns to identify malware based on the features present in the data.To better understand how federated learning is applied, consider a scenario with multiple organisations—each of which runs their own fleet of devices and computers that may encounter different types of malware.Step 1: Local Data Collection and PreprocessingEach organization’s devices gather local data, such as logs from network traffic, file execution metadata, and system behavior patterns. For example, in one organization, devices might detect a spike in traffic to certain suspicious IP addresses, which suggests potential malware communications. In another organization, devices might record unusual system file modifications or execution of untrusted code, hinting at ransomware or trojans. Each device preprocesses this data locally, extracting features such as file hash values, application programming interface (API) calls, memory usage, and I/O behavior, creating a dataset labeled with malware or benign labels (Table 4.1).Table 4.1Example of a Program Behaviour LogFeatureDescriptionExample ValueFile hashUnique hash of the fileefgh5678abcd1234Memory usageAmount of memory used by the process256 MBAPI callsSpecific API calls made by malwareNtCreateFileExecution timeTime taken to execute the program2.5 secNetwork IPsIP addresses contacted by program192.168.0.101
Step 2: Local Model TrainingEach device trains a local machine learning model, such as a random forest or neural network, on this preprocessed data. These local models learn to identify patterns in the features that correspond to malware activity. For instance, a model might learn that frequent access to certain API calls combined with communication to suspicious IP addresses often correlates with ransomware.At this stage, only the models are trained on the device—no raw data is shared with external entities. This ensures that sensitive information, such as network logs or specific file behaviours, remains private to the organisation.
Step 3: Federated Aggregation of Local ModelsAfter training, each device sends its locally trained model to a central server. Importantly, this does not involve sending the underlying data, only the model parameters (such as the weights of a neural network). The central server aggregates these local models to create a global model, using techniques like Federated Averaging. This global model benefits from the knowledge gained across all devices, without ever accessing the raw data from any of them.For example, the global model might combine knowledge of file behaviours indicative of malware from one organization with suspicious network patterns from another, allowing it to detect a broader range of threats than any individual device’s local model could (Table 4.2).Table 4.2Aggregation of Local model with weight of contributionOrganizationLocal model accuracyContribution to global modelOrg A92%High weightOrg B88%Medium weightOrg C90%High weight
Step 4: Model Updates and DeploymentThe aggregated global model is sent back to each participating device, where it is deployed for real-time malware detection. Each device now benefits from a model trained on data from across the network, enhancing its ability to detect malware that may not have appeared in its local environment but was encountered by other devices.For example, if Org A’s environment saw new strains of spyware, and Org C experienced an influx of ransomware variants, the global model would now be capable of detecting both types across all participating devices.

4.2.2.3.2 Performance MetricsEvaluating the effectiveness of FL-based malware detection systems requires robust performance metrics that reflect the system’s ability to accurately identify threats while addressing unique challenges such as data heterogeneity and resource constraints. Key metrics for assessing these systems include detection accuracy, precision, recall, F1-score, communication overhead, and convergence time, all of which provide insight into both the technical performance and practical feasibility of the approach.Detection accuracy measures the proportion of correctly identified samples, both benign and malicious, and serves as a baseline for evaluating the model’s reliability. Precision and recall offer deeper insights into detection quality, where precision assesses the proportion of true positives among all positive predictions, and recall measures the proportion of true positives detected among all actual malicious samples. For example, a system deployed across various organizations may yield high recall in detecting malware but low precision if it misidentifies legitimate software as malicious, leading to false alarms. The F1-score balances precision and recall, offering a single metric for overall detection performance, which is particularly important when malware datasets are imbalanced, as malicious samples often constitute a minority of total data.FL-based systems introduce additional considerations such as communication overhead and convergence time, which measure the cost of distributed training and the time taken for the global model to stabilize, respectively. Communication overhead quantifies the bandwidth required to exchange model updates between participating devices, a critical factor in resource-constrained environments like IoT ecosystems or mobile networks. Convergence time assesses how quickly the system can adapt to new malware threats, which is crucial for real-time applications. For instance, in an FL-based malware detection system deployed across edge devices, rapid convergence ensures timely updates to counter emerging malware variants while minimizing interruptions to normal operations.Furthermore, the diversity and distribution of data in FL settings require evaluating the robustness of the model to non-iid data, as malware samples may vary significantly across devices or regions. A robust system should maintain high performance even when training data is not evenly distributed or follows different patterns. Similarly, privacy preservation metrics assess the system’s ability to protect sensitive data during the training process, ensuring compliance with regulations like GDPR and avoiding leakage of proprietary information. By combining traditional performance metrics with FL-specific considerations, such as communication efficiency and robustness to heterogeneity, malware detection systems can be rigorously evaluated to ensure they meet the demands of modern cybersecurity challenges. These metrics not only gauge technical performance but also determine the practicality of deploying FL-based solutions across diverse environments, from enterprise networks to IoT ecosystems.
4.2.2.3.3 Example Use Case: Federated Malware Detection in IoT NetworksConsider an IoT-based smart home network, where each device—such as smart TVs, refrigerators, and home security systems—can be compromised by malware targeting vulnerabilities specific to IoT systems. In a traditional centralized system, data from each device would need to be sent to a cloud server for analysis, which introduces privacy concerns and increases latency (Fig. 4.4).Diagram illustrating a network communication process. Multiple devices send signals to two separate transmission towers, which then relay the signals to a cloud, representing data storage or processing. Arrows indicate the direction of data flow from devices to towers and then to the cloud.Fig. 4.4Example configuration use caseUsing federated learning, each IoT device can train its own local model to detect potential malware based on its unique activity patterns for instance consider unusual traffic from a smart thermostat. These local models are then aggregated at the edge or cloud level, creating a global model capable of detecting malware across all connected devices without compromising user privacy. If a new malware strain affecting smart refrigerators is detected in one household, the global model can learn from that example and prevent similar attacks across all smart homes in the network.

4.2.2.4 BenefitsEnhanced Privacy: User data remains on their devices, protecting sensitive information. This decentralized approach ensures that personal and proprietary data is not exposed to potential security risks.Adaptability: Continuous local training ensures models are up-to-date with the latest malware variants. As new malware is detected on individual devices, the local models adapt and improve, which then contributes to the global model.Resource Efficiency: Distributed training reduces the computational load on centralized servers. Each device only needs to process its own data, which can lead to more efficient use of resources and faster model updates.

4.2.3 Federated Learning for Phishing DetectionPhishing remains one of the most common and damaging types of cyberattacks, where attackers trick individuals into revealing sensitive information, such as passwords, financial details, or personal data, by posing as legitimate entities. Phishing detection systems aim to identify and mitigate such threats through a combination of rule-based, heuristic, and machine learning techniques. Federated learning introduces a privacy-preserving, scalable, and adaptive approach to enhance phishing detection, addressing the limitations of traditional methods.4.2.3.1 OverviewBefore machine learning, phishing detection relied on rule-based systems that scanned emails or web pages for suspicious keywords, URLs, or metadata. While these systems were effective in identifying known phishing patterns, they struggled with novel, sophisticated attacks that used obfuscation techniques or evolved over time. For example, attackers could bypass such systems by subtly altering the spelling of words, using visually similar domain names, or embedding malicious links in QR codes [15].Machine learning offered a significant advancement by analyzing features extracted from emails, web pages, and URLs to identify phishing attempts. Features such as domain age, URL length, email headers, and hyperlink behavior were used to train models capable of detecting previously unseen phishing attacks. However, ML-based phishing detection systems faced several challenges:1.Privacy Concerns: Training ML models required collecting vast amounts of user data, including sensitive emails, URLs, and browsing behavior, raising significant privacy concerns. 2.Adaptability: Centralized models struggled to quickly adapt to new phishing tactics, as they relied on periodic retraining with updated datasets. 3.Scalability: Transferring large amounts of data from distributed devices to a central server for training incurred high communication costs and latency, making real-time detection challenging. Federated Learning addresses these issues by enabling decentralized training of phishing detection models, allowing devices to collaboratively improve detection capabilities without sharing raw data.
4.2.3.2 Architecture and ImplementationFederated Learning can be applied to phishing detection by enabling email clients or web browsers to train local models on their user interactions. These local models are then aggregated to improve the global phishing detection model. Let delves into it by bringing an example:Consider a scenario involving multiple organizations or individual users who encounter phishing attempts in different forms:4.2.3.2.1 Step 1: Local Data Collection and PreprocessingEach device collects phishing-related data from emails, URLs, and web traffic. For instance, an email client may identify suspicious messages using indicators such as mismatched sender domains or requests for sensitive information. A browser might detect phishing websites based on unusual domain behavior, such as recently registered domains or excessive redirects.Preprocessing extracts features from this data to build a dataset for training. Examples of features include (Table 4.3):Table 4.3Phishing local dataFeatureDescriptionExample valueDomain ageAge of the domain in days5 daysURL lengthTotal character count of the URL120HTTPS usageWhether the site uses HTTPSNoKeyword presenceKeywords like “login” or “verify” in the URLYesRedirection countNumber of times the URL redirects3Sender email domainDomain in the sender’s email addressexample.comFor example, a suspicious email might contain the sender domain m1crosoft-support.com (a spoof of Microsoft) and an embedded link leading to a newly registered domain with several redirects.
4.2.3.2.2 Step 2: Local Model TrainingEach device trains a phishing detection model on its local dataset. For example, a machine learning model like a gradient boosting classifier or a neural network might analyze features to determine whether an email or URL is phishing or legitimate. A model trained locally on a single device might learn that certain keyword patterns or domain characteristics correlate with phishing attempts.
4.2.3.2.3 Step 3: Federated Aggregation of Local ModelsOnce the local training is complete, each device sends its model parameters such as weights for a neural network to a central server. These parameters, rather than raw data, are aggregated using methods like Federated Averaging to create a global model.The global model benefits from diverse data across all devices. For instance, one user’s local model might have learned to identify spear-phishing attacks targeting executives, while another user’s model might specialize in identifying phishing websites related to financial scams. Aggregating these models enables the global model to detect a wider variety of phishing (Table 4.4).Table 4.4Aggregation of local phishing dataDevice/userLocal model accuracyContribution to global modelUser A (Corporate)90%High weightUser B (Home user)85%Medium weightUser C (IoT device)88%Medium weight
4.2.3.2.4 Step 4: Model Updates and DeploymentPhishing threats in the context of smart cities present a unique and complex challenge. Smart cities rely heavily on interconnected systems, such as smart grids, intelligent traffic management, and IoT-based public utilities. Attackers can exploit these systems using phishing attacks to compromise email accounts, social engineering attacks on utility operators, or malicious links targeting public kiosks or smart devices. A federated learning-based phishing detection system can play a pivotal role in safeguarding these critical infrastructures without breaching the privacy of citizens or operators.Imagine a smart city where various public and private entities—including municipal offices, hospitals, traffic systems, and utility providers—regularly exchange data. Each entity uses its devices and systems, which are vulnerable to phishing attacks tailored to their specific context. A centralized phishing detection system would require collecting sensitive data from all these entities, creating significant privacy and trust concerns. Federated learning, however, allows each entity to train a phishing detection model on its own environment while contributing to a global, privacy-preserving model.
4.2.3.2.5 Implementation Steps in Smart City ContextStep
