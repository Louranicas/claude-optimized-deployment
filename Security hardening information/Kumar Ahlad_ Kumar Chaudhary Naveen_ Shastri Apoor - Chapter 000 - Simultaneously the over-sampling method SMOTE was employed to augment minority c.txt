# Security Chapter Extract
Book: Kumar, Ahlad_ Kumar Chaudhary, Naveen_ Shastri, Apoorva S._ Sing - Digital Defence_ Harnessing the Power of Artificial Intelligence for Cybersecurity and Digital Forensics (2025, CRC Press) - libgen.li
Chapter: 000 - Simultaneously, the over-sampling method, SMOTE, was employed to augment minority classes according to the specified sampling strategy. A pipeline incorporating SMOTE and Random Under Sampler was constructed and applied to the training data, resulting in a balanced dataset denoted as X train res and y train res. Subsequently, a Bagging Classifier was utilized with 25 estimators and a random state for model training. To evaluate the model’s performance, cross-validation was employed to obtain a robust accuracy estimate. The model demonstrated promising results across five folds. The classification report revealed detailed metrics for each class, providing insights into the model’s performance on individual categories. Additionally, overall accuracy, classification error, average precision, recall, and F1 score were computed, demonstrating the model’s effectiveness in addressing the imbalanced dataset and accurately classifying network traffic instances. The AdaBoost Classifier was trained with 50 estimators and a random state, utilizing the balanced dataset (X train res and y train res). Cross-validation with five folds was employed to obtain a reliable accuracy estimate. Performance evaluation on the test set demonstrated strong classification results, highlighting the model’s effectiveness in accurately classifying network traffic instances. The Bernoulli Naive Bayes (NB) Classifier was trained on the balanced. On the test set, the model showcased robust classification performance. Then two NB classifiers were explored in this study. Firstly, the Gaussian NB model was trained and evaluated. And, the study extended to multinomial NB, incorporating MinMax scaling for feature normalization. The model, trained on the scaled dataset, provided a detailed classification report. Continuing the evaluation of different classifiers, a Random Forest Classifier (RFC) was employed, followed by a K-Nearest Neighbors (KNN) Classifier and a Decision Tree Classifier (DTC). For RFC, KNN, and DTC, classification reports were generated, providing detailed insights into precision, recall, and F1 score metrics for each class, contributing significantly to the comprehensive understanding of classifier performance. The RFC, known for its ensemble learning approach, was adept at capturing intricate patterns in the data, reflected in its robust classification results. The KNN Classifier, relying on data proximity for classification, demonstrated competitive performance, indicating its suitability for the task at hand. Meanwhile, the DTC, employing a tree-like model of decisions, showcased its effectiveness in handling complex decision boundaries, ensuring accurate classification of network traffic instances. These analyses elucidate the strengths and weaknesses of each model, aiding in the selection of the most suitable classifier for botnet host detection tasks. Overall, these assessments serve as a crucial foundation for the subsequent discussion and conclusions of this study, providing valuable insights into the efficacy of different machine-learning algorithms in the context of botnet host detection using the CICIDS-2017 dataset.
Security Relevance Score: 6
Word Count: 2186
Extracted: 2025-06-13 23:40:52

---

Simultaneously, the over-sampling method, SMOTE, was employed to augment minority classes according to the specified sampling strategy. A pipeline incorporating SMOTE and Random Under Sampler was constructed and applied to the training data, resulting in a balanced dataset denoted as X train res and y train res. Subsequently, a Bagging Classifier was utilized with 25 estimators and a random state for model training. To evaluate the model’s performance, cross-validation was employed to obtain a robust accuracy estimate. The model demonstrated promising results across five folds. The classification report revealed detailed metrics for each class, providing insights into the model’s performance on individual categories. Additionally, overall accuracy, classification error, average precision, recall, and F1 score were computed, demonstrating the model’s effectiveness in addressing the imbalanced dataset and accurately classifying network traffic instances. The AdaBoost Classifier was trained with 50 estimators and a random state, utilizing the balanced dataset (X train res and y train res). Cross-validation with five folds was employed to obtain a reliable accuracy estimate. Performance evaluation on the test set demonstrated strong classification results, highlighting the model’s effectiveness in accurately classifying network traffic instances. The Bernoulli Naive Bayes (NB) Classifier was trained on the balanced. On the test set, the model showcased robust classification performance. Then two NB classifiers were explored in this study. Firstly, the Gaussian NB model was trained and evaluated. And, the study extended to multinomial NB, incorporating MinMax scaling for feature normalization. The model, trained on the scaled dataset, provided a detailed classification report. Continuing the evaluation of different classifiers, a Random Forest Classifier (RFC) was employed, followed by a K-Nearest Neighbors (KNN) Classifier and a Decision Tree Classifier (DTC). For RFC, KNN, and DTC, classification reports were generated, providing detailed insights into precision, recall, and F1 score metrics for each class, contributing significantly to the comprehensive understanding of classifier performance. The RFC, known for its ensemble learning approach, was adept at capturing intricate patterns in the data, reflected in its robust classification results. The KNN Classifier, relying on data proximity for classification, demonstrated competitive performance, indicating its suitability for the task at hand. Meanwhile, the DTC, employing a tree-like model of decisions, showcased its effectiveness in handling complex decision boundaries, ensuring accurate classification of network traffic instances. These analyses elucidate the strengths and weaknesses of each model, aiding in the selection of the most suitable classifier for botnet host detection tasks. Overall, these assessments serve as a crucial foundation for the subsequent discussion and conclusions of this study, providing valuable insights into the efficacy of different machine-learning algorithms in the context of botnet host detection using the CICIDS-2017 dataset.


8.3.2 PCA and TSNE for Detection
In this phase, the preprocessing of the CICIDS-2017 dataset was conducted to ensure data integrity and enhance the quality of features for subsequent analysis. The dataset was initially examined for inconsistencies, such as leading spaces in feature names, which were promptly removed. Following this, features containing negative values were adjusted to be non-negative, preserving the integrity of the dataset. Columns with zero variance, indicating no variability within the dataset, were identified and removed. Additionally, rows containing infinite or missing values were dropped, further refining the dataset. Duplicate rows were identified and subsequently eliminated to prevent data redundancy. Lastly, columns with identical values were detected and removed, reducing redundancy in feature representation (Figure 8.1).



Long Description for Figure 8.1
The flowchart outlines a machine learning pipeline for analyzing the CICIDS2017 dataset, which includes scenarios like DDoS attacks, port scans, and web attacks. The process starts with data preprocessing, including dataframe concatenation, label encoding, and balancing using SMOTE and RandomUnderSampler. Dimensionality reduction is applied with PCA and t-SNE. The processed data is then passed through various machine learning models, such as AdaBoost, Naive Bayes variants, Random Forest, K-Nearest Neighbors, Bagging, and Decision Tree. Performance metrics, including AUC ROC, accuracy, precision, recall, and F1 score, are used for evaluation, with cross-validation for robustness. Finally, the results are visualized to provide insights into the models’ performance.

FIGURE 8.1 System architecture for botnet host detection using advanced ML techniques.

These preprocessing steps culminated in a clean and refined dataset ready for the subsequent stages of analysis. The resulting dataset was of dimensions (2,830,743 × 79) and was utilized for the subsequent analyses in this part of the study. Following the consolidation of the dataset from multiple divisions, an initial exploratory analysis unveiled several trivial columns (’id’, ’Flow ID’, ’Src IP’, ’Src Port’, ’Dst IP’, ’Dst Port’, ’Timestamp’) that were deemed redundant and subsequently removed to streamline the dataset. This meticulous data preprocessing strategy was complemented by the elimination of redundant columns, thus optimizing the dataset further. The result was a meticulously curated dataset, purged of extraneous information and ambiguous labels, laying the groundwork for focused analysis and precise model training in the pursuit of advanced botnet host detection.
After dataset subsampling, dimensionality reduction techniques were employed to facilitate effective data visualization. Initially, Principal Component Analysis (PCA) was leveraged to condense the feature space into two dimensions. The resultant PCA projection, presented in the form of a scatter plot, offered a concise representation of the dataset. Each data point depicted on the plot corresponded to a distinct data instance, with color encoding denoting different classes, thereby simplifying the discernment of potential clusters or patterns within the dataset. In the visualization of the PCA projection of CICIDS 2017 in Figure 8.2, the first plot 2a reveals a preponderance of benign detections, characterized by a cohesive clustering pattern with limited variation along the principal components. Conversely, the isolated depiction of bot detection in plot 2b manifests an inadequate degree of linearity and continuity, indicative of pronounced clustering within the bot detection instances, thereby implying a challenge in extracting discernible feature representations for machine-learning algorithms. In the subsequent Figure 8.3, illustrating PCA projections of the Improvised CICIDS 2017 dataset, the initial plot 3a showcases an accentuation of linearity across the entire dataset, coupled with a sparse occurrence of extraneous outliers. Furthermore, in plot 3b, dedicated to isolated botnet detection, a conspicuous augmentation of linearity and continuity is observed, accompanied by the subsequent dissolution of clustered patterns.



Long Description for Figure 8.2
The first plot, "(a) PCA Projection of entire detection," displays a wide distribution of data points across the first and second principal components, with various detection types like "BENIGN," "Bot," "DDoS," and "Web Attack" represented by different markers. The data points show overlapping clusters and some outliers. The second plot, "(b) PCA projection of bot detections exclusively," focuses on the "Bot" category, revealing two distinct clusters in the PCA space. These plots visually separate different network traffic types, with a particular focus on the clustering of bot-related detections.

FIGURE 8.2 Plot for principal components analysis (PCA) in two components of CICIDS 2017 dataset: (a) PCA projection of entire detection and (b) PCA projection of bot defections exclusively.




Long Description for Figure 8.3
The first plot, "(a) PCA Projection of the entire detection," shows data points categorized into six classes: BENIGN, DDoS, DoS GoldenEye, DoS Hulk, DoS Slowhttptest, and DoS Slowloris. The data points form distinct clusters along the axes, with a legend indicating the different categories. The second plot, "(b) PCA projection of botnet detections exclusively," focuses on botnet traffic, where data points form a tight diagonal cluster. Both plots help visualize the separation and clustering of network traffic, with the first providing a broader view and the second focusing on botnet-specific traffic.

FIGURE 8.3 Plot for PCA in two components of the improvised CICIDS 2017 dataset: (a) PCA projection of the entire detection and (b) PCA projection of botnet detections exclusively.

Additionally, t-distributed Stochastic Neighbor Embedding (t-SNE) was employed as a non-linear dimensionality reduction method. This technique aimed to capture complex relationships between features that might not be apparent in higher-dimensional spaces. The t-SNE projection, visualized in another scatter plot, offered a more intricate view of the dataset. Similar to PCA, distinct classes were represented by different colors, enabling a more nuanced understanding of the data distribution.
Similarly, in the representation of the t-SNE projections for the improvised CICIDS 2017 dataset in Figure 8.4, the distribution of the benign detection is predominantly central within however the instances of the same category are bundled up closer in the first plot 4a in comparison to the earlier plots. The second plot 4b again displays that the reduction in dimensions has led to the mitigation of non-linearity and discontinuity, which means that subsampled data points have been brought close to a reduced distance.



Long Description for Figure 8.4
The two subplots illustrate t-SNE visualizations of network traffic data. The first subplot displays data points across two dimensions labeled "First Embedding Dimension" and "Second Embedding Dimension," with points categorized into various types, including "BENIGN," "Botnet," "DDoS," and more. These points form distinct clusters, with the "Botnet" category standing out. The second subplot zooms in on the "Botnet" category, showing a narrower range of points that form a linear pattern.

FIGURE 8.4 Plot for t-SNE in two components of the improvised CICIDS 2017 dataset: (a) t-SNE visualization of the entire detection and (b) t-SNE visualization of botnet detections exclusively.

Both PCA and t-SNE projections were instrumental in revealing the underlying structure of the subsampled dataset. These visualizations served as a foundation for subsequent analyses, guiding the selection of appropriate machine-learning algorithms and feature engineering techniques.
By transforming the high-dimensional data into two dimensions while preserving essential patterns, these visualizations enhanced the researchers’ ability to comprehend the complex relationships within the dataset, ultimately contributing to the refinement of the next-gen botnet host detection model. In the data preparation phase, a balanced dataset was created to ensure unbiased model training and evaluation. All malicious instances were extracted, forming the ’all malicious’ subset, while a representative sample of 1,000,000 benign instances was randomly selected from the ’improved df’ dataset. This subset, denoted as ’benign 1M’, was split into training and testing sets, with 500,000 instances in each. For training, benign instances were labeled as 1, while malicious instances were labeled as −1, facilitating binary classification. To validate the model effectively, a validation set was established using a 15% portion of the combined benign and malicious test data. This validation set, labeled ’X val’, ’y val’, and ’label val’, allowed for fine-tuning the model’s hyperparameters and detecting potential overfitting. The remaining 85% of the combined test data formed the final test set, denoted as ’X t’, ’y t’, and ’label t’. This meticulous partitioning ensured that the training, validation, and test sets were representative of both benign and malicious instances, providing a robust foundation for the subsequent training and evaluation of the next-gen botnet host detection model. The class distribution was carefully examined in each dataset subset, ensuring a balanced representation essential for the effectiveness of the ML algorithms applied.
In the model fine-tuning phase, an extensive grid search was conducted to optimize hyperparameters, specifically focusing on various scalers and the number of principal components (n components) for PCA. The performance of each combination was evaluated using the validation set, measuring key metrics like area under the receiver operating characteristic curve (AUROC). The objective was to identify the best scaler and PCA configuration that maximized anomaly detection accuracy.
Following the grid search, the top-performing combination of scaler and PCA was selected based on the highest AUROC score. This best configuration was then applied to test data containing different malicious labels and benign instances. Each class’s performance was evaluated individually, utilizing metrics such as precision, recall, and F1-score to assess the model’s ability to accurately distinguish between benign and specific malicious activities. This comprehensive evaluation strategy ensured a robust assessment of the model’s effectiveness across various classes, contributing crucial insights into its real-world applicability for next-gen botnet host detection.
In the interpretability phase, the model’s predictions were examined using SHapley Additive exPlanations (SHAP) to gain insights into the features’ impact on the classification decisions. A subsample of the test data was selected to enhance computational efficiency while retaining the dataset’s representativity. SHAP values were computed for this subsampled data using an explainer, shedding light on the significance of each feature in the model’s predictions.
The SHAP waterfall plot for the first prediction illustrated the step-by-step contribution of each feature towards the final classification outcome. This visualization provided a clear understanding of which features played pivotal roles in distinguishing between benign and malicious instances. Additionally, to provide context, a scatter plot was generated as shown in Figure 8.5, displaying the relationship between ’Bwd Packet Length Mean’ and ’Packet Length Mean,’ two features crucial for the classification process. The plot was annotated with labels denoting different classes, aiding in the interpretation of the data distribution concerning the model’s decisions. Through these visualization, the researchers gained valuable insights into the model’s inner workings, facilitating a deeper understanding of its decision-making process and enhancing the overall transparency of the next-gen botnet host detection system.



Long Description for Figure 8.5
The plot shows the relationship between the mean backward packet length (x-axis) and the mean packet length (y-axis) for different network traffic types. The x-axis ranges from 0 to 4000, and the y-axis from 0 to
