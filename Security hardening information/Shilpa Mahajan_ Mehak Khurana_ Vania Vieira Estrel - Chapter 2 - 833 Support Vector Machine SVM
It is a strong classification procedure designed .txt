# Security Chapter Extract
Book: Shilpa Mahajan_ Mehak Khurana_ Vania Vieira Estrela - Applying Artificial Intelligence in Cybersecurity Analytics and Cyber Threat Detection (2024, WILEY) - libgen.li
Chapter: 2 - 8.3.3 Support Vector Machine (SVM)
It is a strong classification procedure designed to find the best line or decision boundary that separates an n‐dimensional space into different classes, precisely assigning new data points to their respective categories. This boundary is known as a hyperplane [10]. The procedure detects crucial points or vectors, referred to as support vectors that aid in defining the hyperplane. This concept is demonstrated in Figure 8.3.
Security Relevance Score: 6
Word Count: 456
Extracted: 2025-06-13 23:40:31

---

8.3.3 Support Vector Machine (SVM)
It is a strong classification procedure designed to find the best line or decision boundary that separates an n‐dimensional space into different classes, precisely assigning new data points to their respective categories. This boundary is known as a hyperplane [10]. The procedure detects crucial points or vectors, referred to as support vectors that aid in defining the hyperplane. This concept is demonstrated in Figure 8.3.


8.3.4 k‐Nearest Neighbors (kNN)
It categorizes data points by assessing their similarity and reallocates new instances to the category that most closely resembles the existing ones [11]. Figure 8.4a,b show the classification of new data that are assigned to what category after applying kNN. This helps whenever any new data appears; it can be easily shifted to a category which suits it more. kNN is adaptable to different kinds of data, making it suitable for various classification tasks. However, the disadvantage of this is its sensitivity to noisy data and careful tuning of the ‘k’ parameter.


Figure 8.2 Working of gradient boosting algorithm.




Figure 8.3 Working of support vector machine algorithm.




8.3.5 Density‐Based Spatial Clustering of Applications with Noise (DBSCAN)
This is unsupervised clustering that algorithm organizes similar data points together by considering the density distribution across the feature space. Its capability includes recognizing clusters of different sizes and shapes within extensive datasets, encompassing even noisy data points and outliers [12]. The number of clusters doesn’t have to be identified in advance in DBSCAN, making it suitable for various clustering tasks, especially when the data has irregular structures. Figure 8.5a,b present results of clusters before and after applying DBSCAN respectively.


Figure 8.4 (a) Before applying K‐NN. (b) After applying K‐NN.


In the forthcoming sections, the study delves deeper into how the ML techniques were employed and their respective impacts on intrusion detection.



8.4 Overview of Dataset
The analysis utilizes the NSL‐KDD dataset to assess the effectiveness of the IDS. This dataset is constructed to simulate real‐world situations, encompassing both normal and attack instances. As compared to its earlier version, the original KDD Cup 1999 dataset, the NSL‐KDD dataset has undergone preprocessing to remove duplications and irrelevant attributes, making it more refined and representative. The NSL‐KDD dataset features two main classes: “normal” and “attack,” further categorized into subtypes like “DoS,” “R2L,” “U2R,” and “Probe” [13]. While challenges from the original dataset persist, including class imbalance and feature selection complexities, the NSL‐KDD dataset has gained widespread adoption in research and industry. By providing a controlled environment for testing and advancing intrusion detection techniques, the NSL‐KDD dataset contributes significantly to the ongoing improvement of network security strategies. The count of normal and anomaly attacks from the dataset was calculated, which can be shown visually as follows in Figure 8.
