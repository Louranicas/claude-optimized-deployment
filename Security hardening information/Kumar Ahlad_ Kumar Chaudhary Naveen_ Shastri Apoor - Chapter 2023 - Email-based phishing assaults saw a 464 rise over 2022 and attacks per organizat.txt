# Security Chapter Extract
Book: Kumar, Ahlad_ Kumar Chaudhary, Naveen_ Shastri, Apoorva S._ Sing - Digital Defence_ Harnessing the Power of Artificial Intelligence for Cybersecurity and Digital Forensics (2025, CRC Press) - libgen.li
Chapter: 2023 - Email-based phishing assaults saw a 464% rise over 2022, and attacks per organization increased by 24%.
Security Relevance Score: 15
Word Count: 2895
Extracted: 2025-06-13 23:40:52

---

Email-based phishing assaults saw a 464% rise over 2022, and attacks per organization increased by 24%.


2.2 Evolution of AI-Based Predicting Techniques
Tracing back to the 1950s in the world of AI, Arthur Samuel did something amazing—he created the first self-learning checkers program.5 This was like a starting point for AI to learn things on its own. Fast forward to today, and AI has grown a lot. It’s not just about playing games; it’s also helping us predict things through smart analysis. Samuel’s early work was like planting a seed, and now we have a big tree of AI predicting and solving problems for us.6 It’s a journey from simple checkers to the complex world of using AI to figure out what might happen in the future. Samuel’s pioneering efforts resonate, laying the foundation for the indispensable role AI plays in foreseeing and addressing tomorrow’s challenges.7 As we dive deep into AI-driven threat prediction in today’s world, understanding the complex nature of potential dangers posed by diverse adversaries becomes critical. From people working alone to organized groups and even countries spying online, the multifaceted threats necessitate a paradigm shift. The threats are like puzzle pieces needing a new way of thinking. This complexity brings up important questions about ethics and laws regarding AI in cybersecurity.
As we trace back to history, we have an interesting timeline which dates back from the 1960s to the 1980s giving rise to the rule-based algorithmic approaches to AI where, MYCIN, an AI program was used for treating blood infections. In 1972 work began on MYCIN at Stanford University in California.8 MYCIN would attempt to diagnose patients based on reported symptoms and medical test results. Thereafter came the era of machine learning in the 1990s. The machine learning algorithmic model worked on the development of decision tree and neural networks similar to our nervous system. These models helped to put forth the information in a more data-driven format allowing the AI to analyze historical data, identify patterns, and make predictions. Key milestones include the popularization of algorithms like Support Vector Machines (SVM) and Random Forests.9 The early 2000s saw a widespread integration of machine learning algorithms into predictive analysis.10 The upsurge of big data technology towards the late 2000s had a significant contribution towards the success of AI’s accurate predictions at a nascent stage enabling the handling of vast datasets and empowering AI models to derive more accurate predictions. The emergence of ensemble methods and gradient boosting algorithms further improved predictive capabilities making its way for the deep learning revolution in the early 2010s making a significant contribution to assisting AI in the role of predictive analysis.


2.3 Threat Analysis with the Help of AI and Cybersecurity11
The growth of AI has made lives of men easy by acting as an intelligent human. These pre-programed AI models-based algorithms help us detect threats and fix them automatically. Cybersecurity includes everything related to safeguarding our data from online criminals looking to steal it and utilize it for malicious purposes, cybersecurity is crucial.12 Sensitive information, information from the public and private sectors, intellectual property, personally identifiable information (PII), and protected health information (PHI) can all fall under this category. It follows that they are obviously open to cyberattacks. A cyberattack is an attack that is initiated by one or more computers with the intention of either taking down the target computer, gaining access to its data, or disabling it. AI capabilities are frequently used to address cyber risks as a reaction to these challenges.


2.4 Types of Cybersecurity Threats13
In the ever-evolving landscape of cybersecurity, predicting and mitigating threats is paramount to safeguarding websites and web applications. Among the myriad cyber threats, some of the most common and pervasive ones include malware, phishing, spear phishing, and Man-in-the-Middle (MitM) attacks.14
Malware: Malware, short for malicious software, constitutes a diverse category encompassing threats like spyware, ransomware, viruses, and worms. Typically infiltrating a system when a user unknowingly clicks on a hazardous link or opens a malicious email, malware poses a significant risk. Once inside a system, it can impede access to critical network components, inflict damage, and pilfer sensitive information. The repercussions of a malware attack can be severe, affecting the overall integrity and security of the targeted system.
Phishing: Phishing attacks are a prevalent form of cyber threat where cybercriminals deploy deceptive emails that appear legitimate. These emails often contain malicious links or attachments. When unsuspecting users click on these links, they inadvertently install malware or disclose sensitive information such as credit card details and login credentials. Phishing attacks are widespread due to their simplicity and effectiveness in exploiting human trust.
Spear Phishing: A more sophisticated iteration of phishing is spear phishing, which specifically targets privileged users like system administrators and high-ranking executives. In spear phishing attacks, cybercriminals craft personalized and convincing messages to deceive their chosen targets. By leveraging detailed information about the victim, these attacks can be highly targeted and difficult to detect, making them a potent threat to organizations.
Man-in-the-Middle (MitM) Attack: A Man-in-the-Middle attack occurs when cybercriminals position themselves between two parties engaged in communication. In this scenario, the attacker can intercept, manipulate, or eavesdrop on the communication, potentially stealing sensitive data. The attacker may also alter responses to the user, leading to misinformation or unauthorized access. MitM attacks pose a pervasive threat to data integrity and confidentiality, making secure communication channels imperative.
As we explore the legal framework for AI-based predictive analytics in cybersecurity, understanding these common threats is crucial. AI plays a pivotal role in predicting and preventing such threats by analyzing patterns, identifying anomalies, and enhancing overall cybersecurity measures. By incorporating advanced technologies, organizations can fortify their defenses against the ever-evolving landscape of cyber threats, ensuring a proactive and resilient cybersecurity posture for the digital future.


2.5 Approaches to Tackle the Threat
In AI, two prominent approaches shape the development of intelligent systems: the Knowledge-Based Approach (KBAI) and the Pattern Recognition Approach. These methodologies serve as fundamental pillars in creating AI systems, each offering unique perspectives on how machines can emulate human-like decision-making.15

2.5.1 Knowledge-Based Approach16
The KBAI is akin to having an expert advisor within an AI system. Here, the wisdom of human experts in a particular field, like medical diagnosis, is encoded into the system. Imagine a digital expert who follows a set of rules—IF-ELSE conditions—derived from human knowledge. This digital expert, or Expert System, comprises a Knowledgebase and an Inference Engine. The Knowledgebase holds the human expert’s insights, while the Inference Engine processes these insights to make decisions. A classic example is MYCIN, designed for medical diagnoses, where explicit rules govern decision-making.17 IBM Watson, a notable AI system, also utilizes a rule-based knowledge representation to tackle complex tasks.


2.5.2 Pattern Recognition Approach
On the flip side, the Pattern Recognition Approach is all about letting machines learn from data.18 Instead of relying on pre-existing human knowledge, this approach leverages machine learning algorithms to extract patterns directly from data. Imagine teaching a system through examples—it learns to recognize patterns and make decisions based on what it has learned. In this realm, pattern recognition is the key. The field involves automatic discovery of regularities in data using computer algorithms. Machine learning, a powerful tool within this approach, enables systems to discern patterns and take actions, such as classifying data into different categories. This method is hailed as a robust approach to AI, where the system adapts to unknown environments by learning from data patterns.
The KBAI is like having a digital expert following explicit rules, while the Pattern Recognition Approach is more about teaching machines to recognize patterns from data. One relies on human-derived knowledge, and the other on the inherent ability of machines to learn from examples. These approaches form the foundation for creating intelligent systems, each with its unique strengths in different scenarios. In the next section, we’ll delve deeper into Machine learning, a vital component of the Pattern Recognition Approach, to understand how it powers AI systems in recognizing and adapting to patterns in data.



2.6 Humanware in Digital Investigations
In the landscape of digital investigations, the concept of humanware underscores the critical role played by human factors in the interaction with technology. Humanware recognizes the importance of human expertise, judgment, and ethical considerations in navigating the complexities of digital forensics and the use of technology in legal proceedings.
Encouraging the growth of a more conscious humanware involves prioritizing certified training courses for Digital Forensics (DF) examiners, lawyers, and judges. By providing specialized training, we empower individuals to understand, interpret, and critically assess the outputs of AI systems.19 This focus on education aims to limit potential pitfalls such as discrimination, bias, margins of error, false positives, and false negatives, which can inadvertently influence decisions.
Moreover, integrating a legal framework into the development of conscious humanware is crucial. Certified training courses should align with legal principles and ethical standards, ensuring that individuals possess the necessary knowledge to navigate the intersection of technology and the law. This, in turn, safeguards against unlawful decisions stemming from AI systems.
By nurturing a more informed and aware humanware, we create a safeguard against the risks associated with the application of AI-based systems. This approach not only mitigates potential biases but also upholds fundamental rights, fostering a legal environment that respects the ethical and legal implications of technological advancements. There have been instances where the technology goes beyond the general conduct and uses the user’s personal information to find the perpetrator of the crime, which at times goes against the fundamental rights of the citizens. This raises the question of whether such information can be used and if yes to what extent. This is something which is spoken across jurisdictions. Trying to shed light on this we shall try to answer this question using the legal maxim Male captum bene retentum in a scenario.
Every legal system knows the fundamental legal question regarding the admissibility of evidence obtained unlawfully. A crucial point lies at the center of the legal dispute: Does testimony gained by unethical tactics, like torture, qualify as fully admissible evidence? Two opposing groups may be discerned in this extreme context: those who maintain that the evidentiary results should be saved in light of the Latin principle of male captum bene retentum, and those who contend that such conclusions are also illegitimate, the fruit of the poisonous tree doctrine.20 This latter premise is justified by the need to protect investigative findings, even if they are obtained by breaking procedural laws that defend the right to a fair trial for those subject to a court order. This theory articulates the difficult synthesis of two incompatible requirements that are hard to reconcile: the need to preserve the safeguards put in place to prevent abuses and violations of internationally recognized fundamental rights, on the one hand, and the need to ensure sources of evidence even by using instruments that are not typical of procedural rules, on the other. To bridge this gap and increase the transparency it is important that we understand the critical role that a more in-depth and considerate approach to the legal considerations of the use of digital technology plays is vital. To accomplish this goal, we wholeheartedly support the development of supervised systems—those that leave interpretability up to the individual—as well as the protection of the rights of all parties involved in the trial by allowing them to participate in the technical operations; this will create a pool of certified IT skills and pave the way for the use of “humanware” in the field of digital forensics.21 We will not be able to benefit from the use of AI-based technologies if we do not follow the routes of a human-centered perspective.


2.7 Cyber Threat vis-à-vis Legal Framework: A Comparative Analysis between India and the European Union

2.7.1 India
In India, the legal framework addressing cyber threats, particularly in the realm of AI, is evolving to keep pace with technological advancements. The Information Technology Act, 2000, forms the backbone of cybersecurity regulations. However, recognizing the growing significance of AI in the digital landscape, efforts have been made to complement this framework.

National Cyber Security Policy: India introduced the National Cyber Security Policy in 2013, emphasizing the need for a secure cyberspace ecosystem.22 While not specifically tailored to AI, the policy lays down the foundation for enhancing overall cybersecurity measures.
Personal Data Protection Bill, 2019 (PDPB): While primarily focused on data protection, the PDPB acknowledges the importance of securing personal data from cyber threats. As AI systems often involve processing sensitive information, the provisions of the PDPB become relevant in the context of AI-based cyber threats.23
National Strategy for Artificial Intelligence: India has proposed a National Strategy for Artificial Intelligence, which includes considerations for the ethical use of AI.24 While not solely focused on cybersecurity, the strategy emphasizes the need for secure and responsible AI applications.

As India continues to refine its legal landscape, the integration of AI-specific provisions within existing cybersecurity and data protection laws is anticipated to become more pronounced.


2.7.2 European Union
In the European Union (EU), the legal framework for cybersecurity and AI is robust, with a strong emphasis on protecting fundamental rights, including privacy. Several regulations are pivotal in this context:

General Data Protection Regulation (GDPR): GDPR is a landmark regulation that sets stringent standards for data protection and privacy. It impacts AI applications by placing restrictions on the processing of personal data, including data used by AI systems. AI applications must adhere to GDPR principles, ensuring lawful and fair processing, transparency, and user rights.25
Network and Information Systems Directive (NIS Directive): NIS Directive establishes measures to enhance the overall level of cybersecurity in the EU.26 It mandates that certain organizations, including operators of essential services and digital service providers, take appropriate security measures and report significant cyber incidents.
Proposed Artificial Intelligence Act: The EU has proposed the Artificial Intelligence Act to regulate AI applications, including those related to cybersecurity.27 The act categorizes AI systems based on risk, with specific provisions for high-risk AI applications. It aims to ensure transparency, accountability, and adherence to fundamental rights in AI development and deployment.

The EU’s legal framework strongly emphasizes aligning AI applications, including those addressing cyber threats, with ethical and legal standards.28 GDPR, in particular, influences how personal data is handled in AI systems, adding a layer of protection against potential cyber threats.



2.8 Comparison
While both India and the EU share common principles in safeguarding against cyber threats related to AI, there are notable differences in their legal frameworks.29 With its comprehensive GDPR and proposed Artificial Intelligence Act, the EU has a more explicit and targeted approach to regulating AI applications, emphasizing user rights and ethical considerations. In contrast, India’s legal landscape is adapting, with existing laws like the IT Act and ongoing efforts such as the PDPB and the National Strategy for Artificial Intelligence.


2.9 Conclusion
The deployment of automated algorithms stands out as a beacon of hope, offering a proactive approach to identify and neutralize cyber threats at their inception. As we look to the future, it becomes increasingly evident that the effectiveness of our cybersecurity measures hinges on the seamless integration of AI technologies capable of autonomously detecting and thwarting evolving threats. The concept of Zeno’s paradox, encapsulated in the perpetual race between the swift rabbit of technological innovation and the steady tortoise of the legal framework, has provided a poignant metaphor for our exploration. In this dynamic dance, the swift rabbit symbolizes the rapid evolution of technology, unveiling new threats with unprecedented speed. The tortoise, our legal system, moves deliberately to establish order and protection in the expansive digital realm. Acknowledging the importance of a human-centered approach in creating and applying intelligent systems, even if automated procedures and AI algorithms are incredibly efficient, human specialists’ judgment and ethical considerations are still crucial. To successfully navigate the intricacies of digital forensics and legal proceedings, it becomes imperative to cultivate a conscious humanware that is supported by recognized training courses and in line with legal standards. As AI continues to play an increasingly integral role in addressing and posing cyber threats, both India and the EU are actively shaping legal frameworks to balance innovation with the protection of fundamental rights and security. The evolving nature of technology calls for continuous adaptation and refinement of these legal structures to effectively address the dynamic landscape of AI in the context of cybersecurity. This calls for collaborative efforts, globally sharing best practices, aligning standards, and fostering a dialogue to ensure a harmonized approach. The legal framework acts as a guiding compass, ensuring the responsible deployment of AI-based predictive analytics, fostering innovation, and safeguarding against malicious uses. A well-crafted legal framework emerges as the stabilizing force in this perpetual race, ensuring a secure and innovative digital future.


Notes

Huggett, N. (2018) Zeno’s paradoxes, Stanford Encyclopedia of Philosophy. Available at: https://plato.stanford.edu/entries/paradox-zeno/ (Accessed: 25 January 12024).
Brighi, R., Ferrazzano, M., and Summa, L. (2020) Legal issues in AI forensics: Understanding the importance of humanware, I-Lex. Available at: www.i-lex.it.
A, A. (2023) Evolving role of AI in cybersecurity: What’s next?, ETCIO. Available at: https://ciosea.economictimes.indiatimes.com/news/security/evolving-role-of-ai-in-cybersecurity-whats-next/104272834 (Accessed: 26 January 2024).
Dellarocas, C. (2023) How genai could accelerate employee learning and development, Harvard Business Review. Available at: https://hbr.org/2023/12/how-genai-could-accelerate-employee-learning-and-development (Accessed: 28 January 2024).
Wiederhold, G. and McCarthy, J. (1992) ‘Arthur Samuel: Pioneer in machine learning’, IBM Journal of Research and Development, 36(3), pp. 329–
