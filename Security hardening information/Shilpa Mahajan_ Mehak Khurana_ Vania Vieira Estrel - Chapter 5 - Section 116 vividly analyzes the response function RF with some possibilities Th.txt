# Security Chapter Extract
Book: Shilpa Mahajan_ Mehak Khurana_ Vania Vieira Estrela - Applying Artificial Intelligence in Cybersecurity Analytics and Cyber Threat Detection (2024, WILEY) - libgen.li
Chapter: 5 - Section 11.6 vividly analyzes the “response function” (RF) with some possibilities. The “recovery function” (RcF) appears in Section 11.7. Section 11.8 presents “supply‐chain” (SC) “risk management” (RM) (alias SCRM) alternatives. Finally, a terse description of the main subjects and research implications can be found in the conclusion.
Security Relevance Score: 26
Word Count: 4994
Extracted: 2025-06-13 23:40:31

---

Section 11.6 vividly analyzes the “response function” (RF) with some possibilities. The “recovery function” (RcF) appears in Section 11.7. Section 11.8 presents “supply‐chain” (SC) “risk management” (RM) (alias SCRM) alternatives. Finally, a terse description of the main subjects and research implications can be found in the conclusion.


11.2 Background

11.2.1 Cybersecurity
CS situates policies, procedures, and technical tools to protect, defend, detect, and correct damage or unauthorized usage, handling, or adjustment of “information and communication technology” (ICT) structures. The rapid ICT pace of change and innovation and the rapidly evolving CT nature further obscure situations. AICS tools help security teams by alleviating risks and bettering security response in case unprecedented drawbacks strike. AICS’s heterogeneity calls for a uniformly embraced and consolidated taxonomy that aids in utilizing AICS. Structured taxonomies will help understand and improve technical procedures and services.
A well‐known NIST CS framework helps realize solutions to safeguard, detect, act in response, and defend against CAs [1, 2]. The NIST framework’s core is fourfold: (i) functions, (ii) categories, (iii) subcategories, and (iv) informative references. The first two levels have 5 CS functions and 23 solutions to catalog the identified AI UCs. The functions provide a comprehensive lifecycle view for managing CS over time. The solution classes itemized under each function offer a good initial point for AI UC recognition to expand CS. The primary purpose of levels’ selection is to facilitate intuitive tagging of the dominant AICS systems. The taxonomy can accommodate a third level by specifying AI‐founded UCs for each CS framework level [2].


11.2.2 Artificial Intelligence
AI systems relate to (a) target applications and (b) their lifecycle states, like research, design, development, deployment, and usage, exhibiting intelligent behavior by analyzing their environment and achieving specific goals with some autonomy. AI denotes different, multiple technologies and applications. AICS describes the desirable and undesirable environmental situations and assigns actions to sequences. The AI taxonomy from defines its (i) core (i.e., learning, planning, reasoning, communications, and data/result perception) and (ii) transversal domains and subdomains. Knowledge representation and different perceptions comprise reasoning. Planning also covers searching and optimization. Learning includes “machine learning” (ML). Communication leads to “natural language processing” (NLP). Perception entails “computer vision” (CV) and audio processing. AI domains embrace but are not circumscribed to “artificial neural network” (ANN), “deep learning” (DL) (alias “deep neural networks” (DNN)), “fuzzy logic” (FL), NLP, “genetic algorithms” (GAs), “evolutionary algorithms” (EAs), “Bayesian optimization” (BO), “support vector machines” (SVMs), metaheuristics, “planning graphs,” “text mining” (TM), “case‐based reasoning” (CBR), “sentiment analysis” (SA), planning graph, CC, intelligent image processing, Internet of Things (IoT), sensor/actuator networks, object recognition, and speech processing [3–15].
AI is large, and multidisciplinary (translational). So, an ample literary corpus addresses various perspectives, e.g., philosophical, technical, operational, and practical. This chapter discusses AICS implications and scenarios. It details how AI methods can identify, safeguard, sense, respond to, and recuperate CS. AICS describes which ecological situations are looked for and unwanted to assign actions to sequences. The core AI domains encompass the main scientific AI areas. Reasoning apportions knowledge representation and distinctive ways of “thinking,” while planning also covers searching and optimization. Communication is related to NLP. Perception is about CV and audio handling [1, 4].
After primary studies, data mining began to feed the up‐to‐date, descriptive analysis phase. Data extraction (i) breaks down each report into its essential parts, (ii) describes the overall relationships and connections, and (iii) amasses qualitative and circumstantial data parameters. The collected qualitative data summarize each preliminary revision to present the contribution and demographic information. Contextual data include details about the CS function, solution type, UCs, and core AI dominion. Both data types are further examined to identify possible connections between the studies.
A taxonomy classifies existing frameworks to identify and evaluate the prospective AICS applications, accounting for the first two CS NIST levels. The core IaaS functions are fivefold:

(1) Identification (IF),
(2) Protection (PF),
(3) Detection (DF),
(4) Response (RF), and
(5) Recovery (RcF).

These functions cover AI tasks, e.g., preventing security attacks, mechanisms to actively look for new CTs and counterattack maneuvers. IaaS controls different CAs’ lifecycle traits for effective defense.



11.3 Identification Function (IF)
The IF stage subsidizes other functions by pinpointing decisive tasks and CTs for systems, public, assets, and data, helping comprehend CS, recognizing gaps, and creating proper risk supervision strategies for the organization’s necessities, CTs, and costs. The various IF solutions appear below.

11.3.1 CS Asset Management (CAM)
It identifies and keeps track of the organization’s information, people, equipment, systems, and buildings to accomplish its goals with minimum risks. It encompasses assets’ discovery, inventories, supervision, and tracking to protect them. CAM’s complexity grows as organizations have more platforms than ever, from IoT operational technology systems to on‐premises and CC services. Assets’ proliferation and remote work have created highly distributed resources that are difficult to manage and inventory. An AI‐centered CAM system can solve many challenges by feeding new intelligence levels to the human team across the following UCs.
Asset inventory management (AIM) is critical to warrant total visibility and control over all extended network assets. AI can foster continuous and automatic discovery of all devices, applications, and customers besides their critical operation classification. With accurate and up‐to‐date inventories, resources can be tracked and analyzed for an RA against known CA vectors. Compliance monitors can spot rogue resources and unauthorized use. Different approaches classify assets through ML algorithms. K‐means clustering can classify the assets according to nuclear power plant requirements concerning safety, functionality, and integrity [3]. A “random forest” (RFor)‐based ML classifier can categorize operating systems and identifies vulnerable network devices [2]. Several studies [4–6] focus on identifying and classifying IoT devices centered on network traffic features. Correspondingly, multiple and multi‐stage ML methods can be used for single‐device identification and classification and are only proper for small IoT networks [5, 6]. A classification problem solution in rapidly evolving, mixed, and dynamic environments can exploit a supervised ML method to allot IoT modules to predefined classes centered on their traffic flow values. There is work on identifying and blocking malware‐infected assets, determining asset criticality, and the RA of individual resources to manage and ensure their security [8].
Automated configuration management (ACM) is a governance process that defines and maintains preferred system states and delivers timely misconfiguration alerts. The ACM system will consistently define the system settings and keep the system, thus only tolerating deviations in a controlled and authorized environment. Tailoring the system’s configuration guarantees the mandatory performance, and its security reduces human error owing to manual or sub‐optimal configuration setups. Dynamic configuration systems exist for online file‐sharing and distributed CC storage established on system features and operating environments using multi‐objective reinforcement learning (RL) and GAs [11]. A fully automated framework for adapting security controls works by observing the user’s behavior and refining high‐level security requirements expressed in human‐friendly language [14]. ACM allows the compliance team to continuously review and test configurations to identify momentarily vulnerable structures to reduce or avoid CT incurrences (CTincs). A SW product line tactic can analyze systemic vulnerabilities automatically [16]. Alternatively, an RFor model application predicts CTincs based on the DNS and BGP protocol misconfiguration and externally discernible malicious activities commencing from the network [17].
Automated security control validation will monitor security RT in changing environments and CT landscapes, e.g., AI for a definitive CS system’s appraisal through a network’s telescope data, a CS framework, or by correlating the CTs, weaknesses, and security measures [2, 4].


11.3.2 Business Environment
A “business environment” (BE) identifies precarious processes and applications that guarantee business continuity amid adversity. BE is vital to business sustainability, responding effectively, and engendering recovery strategies. AI can automate this process via the following UC. Business impact analysis is crucial to determine critical BE functions and applications by evaluating CTincs’ impacts on the business. AI can automate business impact analysis by economic RA based on a known attack vector or by calculating the CT feasibility and the probability of high‐impact security events in critical businesses. Researchers gauge the financial CT risks in different BEs using other known attack profiles’ modeling, rare‐event simulation, or linking the corporation’s intent to attackers’ aptitudes to guide a scenario breakdown to find its impact on assets [18].


11.3.3 Governance
Governance embroils procedures, processes, and policies for understanding environmental and operational requisites, perceiving the organization’s regulatory necessities, helping know an organization’s responsibilities, and affording CT information to the management. AI can administer policies or automate the retrieval of strategic “vulnerability risk indicators” (VRIs). So, a future goal is an early‐warning system to detect and indicate risk development vs. time attributable to red flags, policy disruptions, or other symptoms. The automatic VRI retrieval embraces the mean time between failures, unpatched systems’ occurrences, risk appetite, or the total attempted breaches. These caveats can turn into knowledge that will assist in preventing CT breaches by rapidly remediating the risk.
Automated policy enforcement (APE) is vital for organizations to ensure compliance with suitable “risk management” (RM) and regulations. AI‐driven policy enforcement in conventional non‐SDN networks that utilize a controller with policy proxies [19]. The controller is a centralized management server that manages SW‐defined middleboxes for regular routers and policy proxies to identify the traffic subject to rules and assist it in policy enforcement.


11.3.4 Risk Assessment
The “risk assessment” (RA) identifies, estimates, and prioritizes CS risks associated with operations, operational resources, and individuals currently or soon. It requires a careful CT analysis, susceptibility, and attack information to determine the extent to which CAs’ could adversely impact the organization and the likelihood of such events. The manual RA process is complex, expensive, and time‐consuming due to countless risk factors, and it requires active human involvement at every stage. The AI‐based RA addresses these challenges by supporting the RM team in the following UCs.
Automated vulnerability identification and assessment (AVIA) modules systematically review structures’ security weaknesses with automated susceptibility identification tools, classification, probing, and prioritization. These automated tools rely on frailty repositories, vendor susceptibility identification announcements, asset management systems, and CTI feeds to identify, classify, and gauge CAincs’ severity while advising remediation.
Automated vulnerability detection is a vital bug isolation step in an organization’s applications, servers, or other structures and assets. SW susceptibility discovery can occur by probing the source code using DL and transfer learning [20], employing text‐mining practices to feed the ML‐based error recognition models as per a “recommendation (alias recommender) system” (RS) that aids programmers in writing secure code. Frailty repositories or social networks aid in detecting emergent SW and cybernetic infrastructural glitches [21]. An exposure identification scheme across the system and network levels models the behavior of cyber‐physical systems (CPS)/IoT under system and network levels’ outbreaks. Then it exploits ML to discover potential attack spaces [22]. FL can find SW and hardware (HW) vulnerabilities in interfaces and applications by injecting unexpected, incorrect, or arbitrary data into a program or interface. Then, it monitors crashes, failed code assertions, undocumented jumps or debug routines, and potential memory leaks. AICS empowers by (i) spotting potential CAs, input initiation, and probable test case generation and (ii) analyzing crashes (Fig. 4). Reasoning and NLP can spawn seeds to enlarge code coverage with more exclusive execution paths as a basic smart fuzzing system step [23]. Test case generation is a studied FL field for web browsers, compilers, CPSs, SW libraries, and simple programs [4, 24–26]. Computerized penetration tests attempt to intrude attack surfaces via known or zero‐day flaws to identify what the attacker can profit from current environments. Devising autonomous RL penetration testing for large networks and microgrid control algorithms undergoes studies [27].
Automated vulnerability classification expedites a deeper data security grasp to accelerate evaluation, automatic classification, and description labeling in reports. A frailty summarization that labels them within an industrial taxonomy model exists [28]. TM to classify weaknesses employs the “Common Vulnerabilities and Exposures” (CVE) list [29].
Vulnerability exploration pinpoints the potential CAs’ vectors that can exploit weaknesses to appraise and achieve them effectively. A model‐driven practice to automatically map adversarial stratagems and shared knowledge to the given system emerges in [2, 4]. A probabilistic model can appraise and manage systemic flaws by rapidly adjusting to the fluid network and attack features [30–33].
Vulnerability assessment and prioritization aim to prioritize weaknesses and provide a valuation report of systems’ frailty exposure and severity. AICS assigns a severity score to each CPS frailty (e.g., equipment, data, business risk, etc.) along with a consequential CA’s ease, severity, and prospective damage. Frailties’ automatic assessment and severity from conflicting weakness reports through the ML pipeline based on the frailty severity and threat profile metrics [30–33]. Vulnerabilities and risk scores help every IoT gadget in the attack graph and are conceived by the network administrator to organize network topologies [33–35].
Automated threat‐hunting searches for security across networks, datasets, and endpoints proactively, seeking potentially malicious, distrustful, or risky organizational activities. It identifies and categorizes eventual CTs ahead through fresh CTI on gathered data. CT hunting is a somewhat new paramount area for early detection. Yet, existing methodologies still work on anomaly‐centered CT detection and oversee abounding external CT knowledge provided by “open‐source (OS) CTI” (OSCTI) [2, 4, 34–37].
Attack path modeling proactively lessens risks, supporting security teams by mapping vulnerable network routes to judge risk, catch vulnerabilities, and take countermeasures to safeguard critical assets, e.g., intrusion alerts or weakness descriptions. All cyber data, including attention alerts, frailties, logs, and network traffic, may matter to simulate attacker/defender deeds and prevent them in RT [2, 4, 37, 38].
Automated risk analysis and impact assessment strengthen the RM team by ingeniously using internal and external risk records to gauge danger and related RT metrics. AI can hurry the RM progress by automating the risk score calculation [39, 40], the inference of the probability of CTincs [41], paramount VRIs’ identification [42], and RA and decision analysis [43, 44] using log data and CTI within and outside the organization.
Predictive intelligence is lawful and relevant and can anticipate CAs, helping deliver an active defense by predicting an intrusion’s type, intensity, and target. DL [45, 46] helps forecast alerts from malicious sources or on a given target using the sequence of previous warnings, historic spam emails, and network traffic data. Malware forecast involves predicting and blocking deleterious files before finishing their payload to prevent CAs rather than remedy them. Malware prediction models with “recurrent neural networks” (RNNs) forecast malicious behavior through machine activity data [47]. CT prediction can advance “cyber resilience” (CR) proactively. Attack prediction schemes may utilize different data types retrieved from news sites and websites, “dark web” (DW) forums, national frailty databanks, CT event reports, and public databases’ flaws/exposure [48].


11.3.5 Risk Management Strategy
RM strategies assist operational risk decisions by forming priorities, risk tolerance, and constraints. It must warrant acceptable risk levels are established and documented along with reasonable resolution times and investment. AI can automate the following activities.
Decision support for risk planning involves implementing a sought‐after countermeasures portfolio within a fixed budget. Formal decision support systems [28, 49, 50] and CA graph modeling [28] can help security designers contrast cost‐effectively with countermeasures and ongoing risk budgets. The CS decision‐making in risk planning matters due to the risk plan’s sensitivity to the decision maker’s attitude towards risk vs. the funding available. Thus, a decision support system implementation is vital for estimating uncertain CA risks affecting an organization, factoring uncertain CT rates, countermeasure expenditures, and assets’ impacts. The GA in Ref. [49] combines countermeasures to block or mitigate CAs, letting users determine the ideal trade‐off between investment costs and resulting risks. Robust optimization supports optimal balance studies between the anticipation, detection, and repression defenses while handling CS uncertainty [50]. An attack graph model can identify a portfolio of security controls to diminish risk [28]. Their model chooses the best possible rules to ascertain that the whole budget does not exceed the organizational budget.
“Supply chain” (SC) “risk management” (RM), aka SCRM, supports menace‐related decisions for identifying, weighing, and managing SC risks. Successful SCRMs necessitate a broad CTs’ view and weaknesses, cost‐effective SC risk planning strategies, and a CR assessment to warrant CS. AI can automate CT analysis and prediction [29], optimal CS risk investment [51], and the SC CR [52].
SCs require a secure, integrated network between the incoming and outgoing chain subsystems. Hence, it is indispensable to understand and predict CTs using internal and CTI resources to limit business disruption. CTI data has been incorporated and used ML to predict CA patterns on cyber SC systems [29]. Optimizing CS risk investments is crucial for SCs to speedily detect, alleviate, and balance security breaches’ impact with the available budget. There are different models for optimal CS investment with a limited budget and a security control portfolio to balance CS [51]. An SC CR appraisal is crucial to protect the SC from cyber intrusions and secure a competitive business advantage. An integrated, ample Dempster‐Shafer (D‐S) approach can build a framework for CR evaluation of an additive manufacturing SC [52].



11.4 Protection Function (PF)
PF assists in the planning and execution of appropriate controls to restrict or contain a potential CS event impact, including technical and procedural guidelines to shield against internal and external CTs proactively. AI can ameliorate the CPS’s resilience through authenticating devices, clients, and other assets, checking customer behavior, automated access control, adaptive training, data leakage prevention and integrity monitoring, automated information defense processes, and protective solutions’ provision to secure the system proactively.

11.4.1 Controlling, Identity, Authentication, and Access
Identity management, authentication, and access (IMAA) control limits admission to accompanying facilities and assets to accredited users, processes, apparatuses, and authorized activities. AI can manage and protect physical and remote access by (a) intelligent client and server authentication, (b) automated access regulation through authorizations, and (c) permissions to prevent unapproved access and its consequences.
AI‐supported user authentication (AISUA) can improve user authentication with physical biometrics, behavioral biometrics, or multi‐factor authentication instead of usernames, passwords, and even one‐time text tokens. Biometrics employs inborn users’ physical traits for identification like iris, blood vessels, fingerprints, and other bio‐signals [53, 54] “Behavioral biometrics” (BB) are inimitably discernible and measurable human activity patterns that can deliver user‐friendly and continuous CS. There are several BBs, including usage behavior and gait [52–54]. The user’s comportment patterns related to a user’s interaction with their own devices is the main basis of the continuous authentication systems via mobile functions and usage data, e.g., accelerometer, pacemakers, intelligent watches, and statistics from different applications’ interactions, to conclude whether the present user remains the same as the individual authenticated beforehand [53]. A continuous authentication scheme can rely on the users’ BBs’ profiles according to their interaction with different office devices for smart offices using CC and an RFor algorithm. Still, these solutions are gradually entering the realm of federated identity management elucidations, raising interest in them [54]. A transparent, non‐intrusive, and continuous authentication scheme that can assist mobile devices’ gait authentication is the required information to corroborate the user’s authenticity as the person walks. Multi‐factor authentication entails a layered methodology to safeguard data and applications requiring two or more credentials for user identity verification or login.
Intelligent HW authentication endorses devices by their credentials or behavior in the network to warrant M2M communication security. Researchers are actively working on sensor/actuator identification and authentication to warrant CPSs’ security. Channel [55], sensor [56], and actuator flaws catch transient and steady‐state parameters as input to the ML model for sensor identification.
“Automated access control” (ACC) restricts systems’ right of entry to authorized users per situations or their organizational roles/regulations. AI techniques help maintain the access control state [57], role mining [58], and situation‐aware decision‐making [59] to prevent unauthorized access and its consequences.
“Role‐based access control” (RBAC) bestows entrance to different customers consistent with their organizational roles. AICS can update and maintain the access control state when exceptions or violations are reported [57] by providing an optimized action plan to reconfigure the RBAC state to facilitate maintenance. An optimal role‐mining, scalable tactic to unearth user‐role and role‐permission associations obtain cues from existing access control lists [58]. Attribute‐based access control considers various pre‐configured attributes related to the user, environment, and access resource. AICS situation‐aware decision‐making performance for attribute‐reliant access control has been tested in fisheries and manufacturing systems [59].


11.4.2 Awareness and Training
This response category covers CS awareness and training for personnel and partners to accomplish their information security responsibilities in compliance with procedures and policies. AI can be used for adaptive and personalized CS training, awareness, or recommendations by automatically selecting content via NLP algorithms [60] or providing an ML‐enabled coach for solution‐guiding hints [61]. Adaptive security awareness and training help overcome training challenges of outdated content, material selection, and acceptable approaches. An adaptive web‐established learning CPS getting up‐to‐date DBpedia training content and giving automated content selection based on a learner’s prior knowledge of information security appears in [60]. On the other hand, programmers were helped by topic modeling or exploiting serious games to recommend/raise secure coding practices awareness [60, 61].


11.4.3 Data Security
Data security administrates information management as per risk strategy for defending sensitive records by (i) shielding information at rest and in transit and (ii) managing the assets’ lifecycle, comprising their decommissioning or disposal. AI can actively prevent data leakage, protect email, block/report malicious domains, and monitor agent‐based integrity for data confidentiality, integrity, and availability.
Data leakage prevention (DLP) encompasses detecting and protecting data breaches, exfiltration, or unwanted data destruction. AICS can surveil data access, information movement, users’ activities [62, 63], automated data sensitivity exposure [64], and APTs’ detection [65] to prevent data leakage. Identifying authorized individuals and how they use sensitive information affords accurate comprehension for data leakage preclusion by observing their behaviors or activities. AI helps monitor user activity to identify abnormal behavior regarding a spike in unusual activities by correlating multiple sources’ data [62, 63]. These needs led researchers to employ an insider CT test dataset from CERT to get data leakage prevention insights for using different temporal representations of user activity or daily activity summaries, email contents, and email networks [62]. A model that only identifies data leakage events during the sensitive period before a staff member leaves an organization appears in [63]. Automated data sensitivity detection identifies and classifies data by analyzing, labeling, and organizing them into relevant groups (viz, confidential, individual, and public) employing shared traits [63], hampering data leakage prevention techniques to monitor users’ actions towards only particular relevant sensitive data portions rather than always pursuing all data. An automated classification practice relying on security similarity to mitigate the sensitive data leakage threat from insiders is in Ref. [64]. Sensitive facts inherent to unstructured data make involuntary data leakage easier [64], which can be mitigated by a content and context‐based information identification scheme using BiLSTM and an attention mechanism.
APTs are targeted CA types that last long and overlook the target network’s defenses. The main purpose of this attack type is to steal data rather than trigger any damage. Researchers are working on efficiently capturing telemetry from endpoints, networks, and clouds to integrate and analyze diverse telemetry to extract “indicators of compromise” (IoCs), anomalies, and other relatable behaviors [65].
Intelligent protection means SW solutions to avert sophisticated email CAs. A spam email tactic traditionally seeks goods and services via unsolicited emails from/to bulk lists. Today, however, it is actively spreading malware, stealing authentication credentials, or committing financial fraud. AI can automate harmful spam protection. Supervised classification and DL‐based [66] techniques can identify RT spam utilizing dynamic inward email data, including general, subject, visual, imagery, and attachment, among other content traits [67].
“Malicious domain blocking and reporting” (MDBR) offers a better security level for email protection by catching up with any evil network traffic from opening spam emails or attachments. AI helps identify suspicious websites for each DNS lookup and block malicious websites that may contain malware, phishing, ransomware, and other CTs. Detecting malicious websites works by training ML algorithms with an opulent collection of harmful and healthy website features. These features can be fourfold [68–72]: website design, domain, URL, and hybrid. A new website categorization method can pinpoint malware or crack websites employing the automated scraping and treatment of too many visual and non‐visual design are trendy from detection results from malicious websites. Supervised ML [68] and DL [69] models can catch evil domain names employing classical domain‐name structures. URL strings’ parts containing linguistic, lexical, contextual, and statistical information can reveal malicious websites. Malicious websites with URL features have been analyzed as input to the ensemble ML and DL models [70]. Hybrid attributes for malevolent website identification help figure out botnets [73] or phishing website detections [71, 72] by combining features related to domain name structure and DNS response, viz resolution source, daily resolution amount, etc.


11.4.4 Information Protection, Processes, and Procedures
Information sources and assets consistent with security strategies, processes, and procedures must be safe. It includes protecting information and establishing, managing, and implementing response, retrieval, and vulnerability supervision plans: AI‐powered backup and an AI‐enhanced frailty management plan sustain processes and procedures for information protection.
AI‐powered backup (AIPB) aims to back up critical data and SW components according to priorities and requirements for efficient backup. AI techniques can perform dynamic backup scheduling and optimized backup scheduling. A dynamic backup system with clever scheduling algorithms improves the stability and predictability of the backup environment that schedules the backup efficiently by determining which backup commences first and which storage goes to that backup to expand efficiency [74]. A 2‐D Markov chain can model data backups and study their scheduling optimization by examining a probabilistic backup policy to initiate at each time slot, regardless of the backup size [75].
AI‐enhanced vulnerability management plans are frameworks designed to proactively shrink risk exposure, which can disrupt and impact the whole system. Aligning the weakness management plan with systemic prerequisites and critical success factors becomes paramount, given the recently reported defenselessness rise. AICS techniques can determine context‐based weakness risk scores and fragility exploitation trends in RT to protect assets and information systems. Context‐based vulnerability risk scoring will help analysts (i) prioritize some particular assets’ or information systems’ risks and (ii) enable them to undertake protective action. An exciting risk prioritization scheme for vulnerability RA consists of an attacker’s model integration to apprehend the invader’s preference for exploiting weaknesses [76]. The risk score corresponds to the criticality and likelihood of the exploitation through a logic‐reasoning engine. A frailty exploitation trend will help the analyst prioritize patching and remediation by envisaging the most probable exploited instabilities. Novel AICS approaches can estimate exploitability and unravel the class imbalance problem to improve ML algorithms’ performance, focusing on (a) liability exploitation prediction using transfer learning to help experts prioritize patch applications [77] or (b) via sequential batch‐learning, i.e., RT, dynamic adaptive learning, which tackles abnormalities and dynamic class imbalance within exploitability prediction [78].


11.4.5 Protective Technologies
Security and resilience for CPSs and assets utilize tamper‐evident features to identify and deter attempts to breach, change, infiltrate, and get the organization’s assets’ knowledge. AI can engender protective ways through “intrusion prevention systems” (IPSs), anti‐virus/anti‐malware solutions, log analysis tools, and protection by deception.
Log analysis appraises computer‐generated event logs to proactively isolate bugs, security concerns, or other risks. AICS log analysis can automate routine tasks to handle large amounts of distributed log data well. Performance tests of assorted supervised ML tactics for detecting malicious “remote desktop protocol” (RDP) in Windows sessions utilizing RDP event logs emerge in [77–79]. Other data presentation arrangements exploited a storytelling scheme to yield a natural language report for recognizing CT information according to users’ knowledge levels [79]. Solutions for a variety of interoperability concerns in log management have emerged. The AI variety issue has been addressed to extract and treat textual records from different sources for satisfactory log feature representation via information retrieval [80]. Likewise, the work in [81] handled security analytics of the heterogeneous log data from different network sensors by employing automated feature extraction and selection techniques.
IPSs monitor the network traffic for apt action to thwart CAs by reporting, obstructing, dropping, or resetting connections through (i) unsupervised isolation forest [82] and (ii) self‐organizing incremental ANNs and SVM‐based IPSs [82–84] for embedded automotive systems and IoT networks, respectively.
Anti‐virus/anti‐malware solutions can scrutinize thousands of files and extract advantageous features to label them as nonthreatening or malware. Anti‐virus programs can detect malware using executables’ retrieved features [83] or dynamic data analysis [84] as an input to ANNs or RNN models.
Protection by deception is a technique to protect critical documents after attackers penetrate the network. AI can generate credible fake text documents to mislead CAs. Decoy files can divert the adversary from the factual target when the invader has already taken the system [85]. This decoy GA‐centered text‐creation handles actual documents’ directness to hard‐to‐comprehend, albeit credible, fake documents.



11.5 Detection Function (DF)
DF enables timely CT event discovery by designing and implementing applicable activities to identify their occurrence. DF is crucial for security as prompt detection will minimize the disruption, comprising (i) actions for the suitable detection of invasions and glitches, (ii) impact assessment, (iii) implementation of a continuous monitoring security framework to verify the defensive measures’ effectiveness, and (iv) appropriate detection processes’ maintenance to ensure the cyber events’ awareness. AI can speed detection by monitoring internal and external sources and expeditiously correlating this information to detect unusual activities to minimize aftermaths. AI solution categories appear below.

11.5.1 Anomalies and Events
Solutions discern and classify abnormal activities by establishing and managing baselines for multiple sources’ operations and data flows. These baselines detect and analyze events to understand CA targets and approaches. “Intrusion detection systems” (IDSs) monitor CPS and network traffic to analyze anomalous and suspicious activities to detect possible system intrusions. IDS was realized as three classification types: binary, multi‐category, or both. Binary classification assumes two labels: normal and attack. Conversely, multi‐category schemes can classify three or more classes. Multi‐category IDS classification discerns between different CA types, displaying users more information for CA remediation. Operational development and assessment metrics for binary and multi‐category IDSs involve benchmark datasets. Datasets examples follow [86–97]:
