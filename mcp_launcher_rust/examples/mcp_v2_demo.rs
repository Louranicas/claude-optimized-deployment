//! MCP V2 Demo - Actor-based Architecture with Message Passing
//! 
//! This example demonstrates the actor-based V2 architecture for MCP management
//! featuring:
//! - Zero-lock message passing between actors
//! - Concurrent server management
//! - Health monitoring actors
//! - Graceful failure handling
//! - Performance metrics collection

use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{mpsc, oneshot};
use tokio::time::sleep;
use tracing::{info, warn, error, debug};
use serde::{Deserialize, Serialize};

// ===== Message Types =====

#[derive(Debug, Clone)]
enum ActorMessage {
    // Server management messages
    LaunchServer { name: String, config: ServerConfig, reply: oneshot::Sender<Result<(), String>> },
    StopServer { name: String, reply: oneshot::Sender<Result<(), String>> },
    GetServerStatus { name: String, reply: oneshot::Sender<Option<ServerStatus>> },
    
    // Health monitoring messages
    HealthCheck { reply: oneshot::Sender<HealthReport> },
    RegisterHealthCheck { name: String, interval: Duration },
    
    // Metrics messages
    RecordMetric { metric: Metric },
    GetMetrics { reply: oneshot::Sender<MetricsReport> },
    
    // System messages
    Shutdown,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ServerConfig {
    name: String,
    port: u16,
    category: String,
    requires_auth: bool,
    capabilities: Vec<String>,
}

#[derive(Debug, Clone, Copy, PartialEq)]
enum ServerStatus {
    Starting,
    Running,
    Stopping,
    Stopped,
    Failed,
}

#[derive(Debug, Clone)]
struct HealthReport {
    total_servers: usize,
    healthy_servers: usize,
    failed_servers: usize,
    uptime_seconds: u64,
}

#[derive(Debug, Clone)]
enum Metric {
    ServerStarted { name: String, duration_ms: u64 },
    ServerStopped { name: String },
    HealthCheckCompleted { duration_ms: u64 },
    RequestProcessed { server: String, duration_ms: u64 },
}

#[derive(Debug, Clone)]
struct MetricsReport {
    total_starts: usize,
    total_stops: usize,
    average_start_time_ms: f64,
    health_checks_performed: usize,
    requests_processed: HashMap<String, usize>,
}

// ===== Actor Implementations =====

/// Main supervisor actor that coordinates all other actors
struct SupervisorActor {
    server_manager: mpsc::Sender<ActorMessage>,
    health_monitor: mpsc::Sender<ActorMessage>,
    metrics_collector: mpsc::Sender<ActorMessage>,
}

impl SupervisorActor {
    fn new(
        server_manager: mpsc::Sender<ActorMessage>,
        health_monitor: mpsc::Sender<ActorMessage>,
        metrics_collector: mpsc::Sender<ActorMessage>,
    ) -> Self {
        Self {
            server_manager,
            health_monitor,
            metrics_collector,
        }
    }
    
    async fn run(mut self, mut rx: mpsc::Receiver<ActorMessage>) {
        info!("üé≠ Supervisor actor started");
        
        while let Some(msg) = rx.recv().await {
            match msg {
                ActorMessage::LaunchServer { name, config, reply } => {
                    // Forward to server manager
                    let (tx, rx) = oneshot::channel();
                    self.server_manager.send(ActorMessage::LaunchServer { 
                        name: name.clone(), 
                        config, 
                        reply: tx 
                    }).await.ok();
                    
                    // Wait for result and record metric
                    let start_time = Instant::now();
                    match rx.await {
                        Ok(result) => {
                            if result.is_ok() {
                                let duration_ms = start_time.elapsed().as_millis() as u64;
                                self.metrics_collector.send(ActorMessage::RecordMetric {
                                    metric: Metric::ServerStarted { name, duration_ms }
                                }).await.ok();
                            }
                            reply.send(result).ok();
                        }
                        Err(_) => {
                            reply.send(Err("Server manager unavailable".to_string())).ok();
                        }
                    }
                }
                ActorMessage::Shutdown => {
                    info!("üõë Supervisor shutting down all actors");
                    self.server_manager.send(ActorMessage::Shutdown).await.ok();
                    self.health_monitor.send(ActorMessage::Shutdown).await.ok();
                    self.metrics_collector.send(ActorMessage::Shutdown).await.ok();
                    break;
                }
                _ => {
                    // Route other messages to appropriate actors
                    debug!("Supervisor forwarding message: {:?}", msg);
                }
            }
        }
        
        info!("üé≠ Supervisor actor stopped");
    }
}

/// Server manager actor responsible for launching and managing MCP servers
struct ServerManagerActor {
    servers: HashMap<String, ServerInstance>,
    metrics_tx: mpsc::Sender<ActorMessage>,
}

struct ServerInstance {
    config: ServerConfig,
    status: ServerStatus,
    started_at: Instant,
}

impl ServerManagerActor {
    fn new(metrics_tx: mpsc::Sender<ActorMessage>) -> Self {
        Self {
            servers: HashMap::new(),
            metrics_tx,
        }
    }
    
    async fn run(mut self, mut rx: mpsc::Receiver<ActorMessage>) {
        info!("üöÄ Server manager actor started");
        
        while let Some(msg) = rx.recv().await {
            match msg {
                ActorMessage::LaunchServer { name, config, reply } => {
                    info!("üì¶ Launching server: {}", name);
                    
                    // Simulate server startup
                    sleep(Duration::from_millis(100)).await;
                    
                    let instance = ServerInstance {
                        config,
                        status: ServerStatus::Running,
                        started_at: Instant::now(),
                    };
                    
                    self.servers.insert(name.clone(), instance);
                    reply.send(Ok(())).ok();
                    
                    info!("‚úÖ Server {} launched successfully", name);
                }
                ActorMessage::StopServer { name, reply } => {
                    if let Some(mut server) = self.servers.get_mut(&name) {
                        server.status = ServerStatus::Stopped;
                        reply.send(Ok(())).ok();
                        
                        self.metrics_tx.send(ActorMessage::RecordMetric {
                            metric: Metric::ServerStopped { name }
                        }).await.ok();
                    } else {
                        reply.send(Err("Server not found".to_string())).ok();
                    }
                }
                ActorMessage::GetServerStatus { name, reply } => {
                    let status = self.servers.get(&name).map(|s| s.status);
                    reply.send(status).ok();
                }
                ActorMessage::Shutdown => {
                    info!("üõë Server manager shutting down all servers");
                    for (name, mut server) in self.servers.iter_mut() {
                        server.status = ServerStatus::Stopped;
                        info!("üî¥ Stopped server: {}", name);
                    }
                    break;
                }
                _ => {}
            }
        }
        
        info!("üöÄ Server manager actor stopped");
    }
}

/// Health monitor actor that periodically checks server health
struct HealthMonitorActor {
    server_manager_tx: mpsc::Sender<ActorMessage>,
    metrics_tx: mpsc::Sender<ActorMessage>,
    start_time: Instant,
}

impl HealthMonitorActor {
    fn new(
        server_manager_tx: mpsc::Sender<ActorMessage>,
        metrics_tx: mpsc::Sender<ActorMessage>,
    ) -> Self {
        Self {
            server_manager_tx,
            metrics_tx,
            start_time: Instant::now(),
        }
    }
    
    async fn run(mut self, mut rx: mpsc::Receiver<ActorMessage>) {
        info!("üè• Health monitor actor started");
        
        // Start periodic health checks
        let mut interval = tokio::time::interval(Duration::from_secs(5));
        
        loop {
            tokio::select! {
                _ = interval.tick() => {
                    let start = Instant::now();
                    self.perform_health_check().await;
                    let duration_ms = start.elapsed().as_millis() as u64;
                    
                    self.metrics_tx.send(ActorMessage::RecordMetric {
                        metric: Metric::HealthCheckCompleted { duration_ms }
                    }).await.ok();
                }
                Some(msg) = rx.recv() => {
                    match msg {
                        ActorMessage::HealthCheck { reply } => {
                            let report = HealthReport {
                                total_servers: 0, // Would query server manager
                                healthy_servers: 0,
                                failed_servers: 0,
                                uptime_seconds: self.start_time.elapsed().as_secs(),
                            };
                            reply.send(report).ok();
                        }
                        ActorMessage::Shutdown => {
                            info!("üõë Health monitor shutting down");
                            break;
                        }
                        _ => {}
                    }
                }
            }
        }
        
        info!("üè• Health monitor actor stopped");
    }
    
    async fn perform_health_check(&self) {
        debug!("üîç Performing health check");
        // In a real implementation, this would check each server's health
        // For demo purposes, we'll just log it
    }
}

/// Metrics collector actor that aggregates performance metrics
struct MetricsCollectorActor {
    metrics: Vec<Metric>,
    server_starts: HashMap<String, Vec<u64>>,
    health_checks: Vec<u64>,
}

impl MetricsCollectorActor {
    fn new() -> Self {
        Self {
            metrics: Vec::new(),
            server_starts: HashMap::new(),
            health_checks: Vec::new(),
        }
    }
    
    async fn run(mut self, mut rx: mpsc::Receiver<ActorMessage>) {
        info!("üìä Metrics collector actor started");
        
        while let Some(msg) = rx.recv().await {
            match msg {
                ActorMessage::RecordMetric { metric } => {
                    match &metric {
                        Metric::ServerStarted { name, duration_ms } => {
                            self.server_starts.entry(name.clone())
                                .or_insert_with(Vec::new)
                                .push(*duration_ms);
                        }
                        Metric::HealthCheckCompleted { duration_ms } => {
                            self.health_checks.push(*duration_ms);
                        }
                        _ => {}
                    }
                    self.metrics.push(metric);
                }
                ActorMessage::GetMetrics { reply } => {
                    let report = self.generate_report();
                    reply.send(report).ok();
                }
                ActorMessage::Shutdown => {
                    info!("üõë Metrics collector shutting down");
                    break;
                }
                _ => {}
            }
        }
        
        info!("üìä Metrics collector actor stopped");
    }
    
    fn generate_report(&self) -> MetricsReport {
        let total_starts: usize = self.server_starts.values().map(|v| v.len()).sum();
        let all_start_times: Vec<u64> = self.server_starts.values()
            .flat_map(|v| v.iter().cloned())
            .collect();
        
        let average_start_time_ms = if all_start_times.is_empty() {
            0.0
        } else {
            all_start_times.iter().sum::<u64>() as f64 / all_start_times.len() as f64
        };
        
        MetricsReport {
            total_starts,
            total_stops: 0, // Would count from metrics
            average_start_time_ms,
            health_checks_performed: self.health_checks.len(),
            requests_processed: HashMap::new(),
        }
    }
}

// ===== Main Demo =====

#[tokio::main]
async fn main() {
    // Initialize tracing
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();
    
    info!("üé¨ MCP V2 Actor-Based Demo Starting");
    info!("=" .repeat(60));
    
    // Create actor channels
    let (supervisor_tx, supervisor_rx) = mpsc::channel(100);
    let (server_manager_tx, server_manager_rx) = mpsc::channel(100);
    let (health_monitor_tx, health_monitor_rx) = mpsc::channel(100);
    let (metrics_collector_tx, metrics_collector_rx) = mpsc::channel(100);
    
    // Create actors
    let supervisor = SupervisorActor::new(
        server_manager_tx.clone(),
        health_monitor_tx.clone(),
        metrics_collector_tx.clone(),
    );
    
    let server_manager = ServerManagerActor::new(metrics_collector_tx.clone());
    let health_monitor = HealthMonitorActor::new(server_manager_tx.clone(), metrics_collector_tx.clone());
    let metrics_collector = MetricsCollectorActor::new();
    
    // Spawn actor tasks
    let supervisor_handle = tokio::spawn(supervisor.run(supervisor_rx));
    let server_manager_handle = tokio::spawn(server_manager.run(server_manager_rx));
    let health_monitor_handle = tokio::spawn(health_monitor.run(health_monitor_rx));
    let metrics_collector_handle = tokio::spawn(metrics_collector.run(metrics_collector_rx));
    
    // Demo: Launch some servers
    info!("\nüöÄ Launching MCP servers via actor system...");
    
    let servers = vec![
        ServerConfig {
            name: "docker".to_string(),
            port: 8001,
            category: "devops".to_string(),
            requires_auth: false,
            capabilities: vec!["container.manage".to_string()],
        },
        ServerConfig {
            name: "kubernetes".to_string(),
            port: 8002,
            category: "devops".to_string(),
            requires_auth: false,
            capabilities: vec!["cluster.manage".to_string()],
        },
        ServerConfig {
            name: "prometheus".to_string(),
            port: 8010,
            category: "monitoring".to_string(),
            requires_auth: false,
            capabilities: vec!["metrics.query".to_string()],
        },
    ];
    
    // Launch servers concurrently
    let mut launch_tasks = Vec::new();
    for config in servers {
        let tx = supervisor_tx.clone();
        let name = config.name.clone();
        
        let task = tokio::spawn(async move {
            let (reply_tx, reply_rx) = oneshot::channel();
            tx.send(ActorMessage::LaunchServer {
                name: name.clone(),
                config,
                reply: reply_tx,
            }).await.ok();
            
            match reply_rx.await {
                Ok(Ok(())) => info!("‚úÖ {} launched via actor system", name),
                Ok(Err(e)) => error!("‚ùå {} failed: {}", name, e),
                Err(_) => error!("‚ùå {} launch timeout", name),
            }
        });
        
        launch_tasks.push(task);
    }
    
    // Wait for all launches to complete
    for task in launch_tasks {
        task.await.ok();
    }
    
    // Let the system run for a bit
    info!("\n‚è≥ System running with health monitoring...");
    sleep(Duration::from_secs(3)).await;
    
    // Get metrics report
    info!("\nüìä Requesting metrics report...");
    let (reply_tx, reply_rx) = oneshot::channel();
    metrics_collector_tx.send(ActorMessage::GetMetrics { reply: reply_tx }).await.ok();
    
    if let Ok(report) = reply_rx.await {
        info!("\nüìà Performance Metrics:");
        info!("  ‚Ä¢ Total server starts: {}", report.total_starts);
        info!("  ‚Ä¢ Average start time: {:.2}ms", report.average_start_time_ms);
        info!("  ‚Ä¢ Health checks performed: {}", report.health_checks_performed);
    }
    
    // Demonstrate message passing performance
    info!("\nüèéÔ∏è  Message Passing Performance Test:");
    let start = Instant::now();
    let message_count = 10000;
    
    for i in 0..message_count {
        let (reply_tx, _reply_rx) = oneshot::channel();
        server_manager_tx.send(ActorMessage::GetServerStatus {
            name: format!("test-{}", i),
            reply: reply_tx,
        }).await.ok();
    }
    
    let elapsed = start.elapsed();
    let msgs_per_sec = message_count as f64 / elapsed.as_secs_f64();
    info!("  ‚Ä¢ Processed {} messages in {:.2}ms", message_count, elapsed.as_millis());
    info!("  ‚Ä¢ Throughput: {:.0} messages/second", msgs_per_sec);
    
    // Shutdown demo
    info!("\nüõë Initiating graceful shutdown...");
    supervisor_tx.send(ActorMessage::Shutdown).await.ok();
    
    // Wait for all actors to finish
    let _ = tokio::join!(
        supervisor_handle,
        server_manager_handle,
        health_monitor_handle,
        metrics_collector_handle
    );
    
    info!("\n‚úÖ MCP V2 Actor Demo Complete!");
    info!("üéØ Key Architecture Benefits Demonstrated:");
    info!("  ‚Ä¢ Zero-lock message passing between actors");
    info!("  ‚Ä¢ Concurrent server management");
    info!("  ‚Ä¢ Fault isolation between actors");
    info!("  ‚Ä¢ High-throughput message processing");
    info!("  ‚Ä¢ Graceful shutdown coordination");
    info!("=" .repeat(60));
}